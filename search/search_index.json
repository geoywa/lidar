{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the lidar package \u00b6 lidar is Python package for delineating the nested hierarchy of surface depressions in digital elevation models (DEMs). It is particularly useful for analyzing high-resolution topographic data, such as DEMs derived from Light Detection and Ranging (LiDAR) data. GitHub repo: https://github.com/giswqs/lidar Documentation: https://lidar.gishub.org PyPI: https://pypi.org/project/lidar Conda-forge: https://anaconda.org/conda-forge/lidar Open in Colab: https://gishub.org/lidar-colab Free software: MIT license Citations - Wu, Q. , (2021). lidar: A Python package for delineating nested surface depressions from digital elevation data. Journal of Open Source Software , 6(59), 2965, https://doi.org/10.21105/joss.02965 - Wu, Q. , Lane, C.R., Wang, L., Vanderhoof, M.K., Christensen, J.R., & Liu, H. (2019). Efficient Delineation of Nested Depression Hierarchy in Digital Elevation Models for Hydrological Analysis Using Level-Set Method. Journal of the American Water Resources Association . https://doi.org/10.1111/1752-1688.12689 ( PDF ) Introduction \u00b6 lidar is a Python package for delineating the nested hierarchy of surface depressions in digital elevation models (DEMs). In traditional hydrological modeling, surface depressions in a DEM are commonly treated as artifacts and thus filled and removed to create a depressionless DEM, which can then be used to generate continuous stream networks. In reality, however, surface depressions in DEMs are commonly a combination of spurious and actual terrain features. Fine-resolution DEMs derived from Light Detection and Ranging (LiDAR) data can capture and represent actual surface depressions, especially in glaciated and karst landscapes. During the past decades, various algorithms have been developed to identify and delineate surface depressions, such as depression filling, depression breaching, hybrid breaching-filling, and contour tree method. More recently, a level-set method based on graph theory was proposed to delineate the nested hierarchy of surface depressions. The lidar Python package implements the level-set method and makes it possible for delineating the nested hierarchy of surface depressions as well as elevated terrain features. It also provides an interactive Graphical User Interface (GUI) that allows users to run the program with minimal coding. Statement of Need \u00b6 The lidar package is intended for scientists and researchers who would like to integrate surface depressions into hydrological modeling. It can also facilitate the identification and delineation of depressional features, such as sinkholes, detention basins, and prairie potholes. The detailed topological and geometric properties of surface depressions can be useful for terrain analysis and hydrological modeling, including the size, volume, mean depth, maximum depth, lowest elevation, spill elevation, perimeter, major axis length, minor axis length, elongatedness. State of the Field \u00b6 Currently, there are a few open-source Python packages that can perform depression filling on digital elevation data, such as RichDEM and whitebox , the Python frontend for WhiteboxTools . However, there are no Python packages offering tools for delineating the nested hierarchy of surface depressions and catchments as well as simulating inundation dynamics. The lidar Python package is intended for filling this gap. Key Features \u00b6 Smoothing DEMs using mean, median, and Gaussian filters. Extracting depressions from DEMs. Filtering out small artifact depressions based on user-specified minimum depression size. Generating refined DEMs with small depressions filled but larger depressions kept intact. Delineating depression nested hierarchy using the level-set method. Delineating mount nested hierarchy using the level-set method. Computing topological and geometric properties of depressions, including size, volume, mean depth, maximum depth, lowest elevation, spill elevation, perimeter, major axis length, minor axis length, elongatedness, eccentricity, orientation, and area-bbox-ratio. Exporting depression properties as a csv file.","title":"Home"},{"location":"#welcome-to-the-lidar-package","text":"lidar is Python package for delineating the nested hierarchy of surface depressions in digital elevation models (DEMs). It is particularly useful for analyzing high-resolution topographic data, such as DEMs derived from Light Detection and Ranging (LiDAR) data. GitHub repo: https://github.com/giswqs/lidar Documentation: https://lidar.gishub.org PyPI: https://pypi.org/project/lidar Conda-forge: https://anaconda.org/conda-forge/lidar Open in Colab: https://gishub.org/lidar-colab Free software: MIT license Citations - Wu, Q. , (2021). lidar: A Python package for delineating nested surface depressions from digital elevation data. Journal of Open Source Software , 6(59), 2965, https://doi.org/10.21105/joss.02965 - Wu, Q. , Lane, C.R., Wang, L., Vanderhoof, M.K., Christensen, J.R., & Liu, H. (2019). Efficient Delineation of Nested Depression Hierarchy in Digital Elevation Models for Hydrological Analysis Using Level-Set Method. Journal of the American Water Resources Association . https://doi.org/10.1111/1752-1688.12689 ( PDF )","title":"Welcome to the lidar package"},{"location":"#introduction","text":"lidar is a Python package for delineating the nested hierarchy of surface depressions in digital elevation models (DEMs). In traditional hydrological modeling, surface depressions in a DEM are commonly treated as artifacts and thus filled and removed to create a depressionless DEM, which can then be used to generate continuous stream networks. In reality, however, surface depressions in DEMs are commonly a combination of spurious and actual terrain features. Fine-resolution DEMs derived from Light Detection and Ranging (LiDAR) data can capture and represent actual surface depressions, especially in glaciated and karst landscapes. During the past decades, various algorithms have been developed to identify and delineate surface depressions, such as depression filling, depression breaching, hybrid breaching-filling, and contour tree method. More recently, a level-set method based on graph theory was proposed to delineate the nested hierarchy of surface depressions. The lidar Python package implements the level-set method and makes it possible for delineating the nested hierarchy of surface depressions as well as elevated terrain features. It also provides an interactive Graphical User Interface (GUI) that allows users to run the program with minimal coding.","title":"Introduction"},{"location":"#statement-of-need","text":"The lidar package is intended for scientists and researchers who would like to integrate surface depressions into hydrological modeling. It can also facilitate the identification and delineation of depressional features, such as sinkholes, detention basins, and prairie potholes. The detailed topological and geometric properties of surface depressions can be useful for terrain analysis and hydrological modeling, including the size, volume, mean depth, maximum depth, lowest elevation, spill elevation, perimeter, major axis length, minor axis length, elongatedness.","title":"Statement of Need"},{"location":"#state-of-the-field","text":"Currently, there are a few open-source Python packages that can perform depression filling on digital elevation data, such as RichDEM and whitebox , the Python frontend for WhiteboxTools . However, there are no Python packages offering tools for delineating the nested hierarchy of surface depressions and catchments as well as simulating inundation dynamics. The lidar Python package is intended for filling this gap.","title":"State of the Field"},{"location":"#key-features","text":"Smoothing DEMs using mean, median, and Gaussian filters. Extracting depressions from DEMs. Filtering out small artifact depressions based on user-specified minimum depression size. Generating refined DEMs with small depressions filled but larger depressions kept intact. Delineating depression nested hierarchy using the level-set method. Delineating mount nested hierarchy using the level-set method. Computing topological and geometric properties of depressions, including size, volume, mean depth, maximum depth, lowest elevation, spill elevation, perimeter, major axis length, minor axis length, elongatedness, eccentricity, orientation, and area-bbox-ratio. Exporting depression properties as a csv file.","title":"Key Features"},{"location":"changelog/","text":"Changelog \u00b6 v0.6.0 - February 27, 2021 \u00b6 Improved documentation Added ArcGIS toolbox tutorials Addressed JOSS review comments v0.5.3 - February 10, 2021 \u00b6 Fixed PyPI markdown rendering error v0.5.2 - February 10, 2021 \u00b6 Added new documentation website ( https://lidar.gishub.org ) Improved JOSS paper Cleaned up source code v0.5.1 - December 12, 2020 \u00b6 v0.2.0 - September 16, 2018 \u00b6 v0.1.6 - May 21, 2018 \u00b6 0.1.5 - May 16, 2018 \u00b6 0.1.3 - May 15, 2018 \u00b6 0.1.0 - May 14, 2018 \u00b6","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v060-february-27-2021","text":"Improved documentation Added ArcGIS toolbox tutorials Addressed JOSS review comments","title":"v0.6.0 - February 27, 2021"},{"location":"changelog/#v053-february-10-2021","text":"Fixed PyPI markdown rendering error","title":"v0.5.3 - February 10, 2021"},{"location":"changelog/#v052-february-10-2021","text":"Added new documentation website ( https://lidar.gishub.org ) Improved JOSS paper Cleaned up source code","title":"v0.5.2 - February 10, 2021"},{"location":"changelog/#v051-december-12-2020","text":"","title":"v0.5.1 - December 12, 2020"},{"location":"changelog/#v020-september-16-2018","text":"","title":"v0.2.0 - September 16, 2018"},{"location":"changelog/#v016-may-21-2018","text":"","title":"v0.1.6 - May 21, 2018"},{"location":"changelog/#015-may-16-2018","text":"","title":"0.1.5 - May 16, 2018"},{"location":"changelog/#013-may-15-2018","text":"","title":"0.1.3 - May 15, 2018"},{"location":"changelog/#010-may-14-2018","text":"","title":"0.1.0 - May 14, 2018"},{"location":"citations/","text":"The level-set algorithm was proposed by Wu et al. (2019): Wu, Q. , Lane, C.R., Wang, L., Vanderhoof, M.K., Christensen, J.R., & Liu, H. (2019). Efficient Delineation of Nested Depression Hierarchy in Digital Elevation Models for Hydrological Analysis Using Level-Set Method. Journal of the American Water Resources Association . DOI: 10.1111/1752-1688.12689 ( PDF ) Applications of the level-set and contour-tree methods for feature extraction from LiDAR data: Wu, Q. , & Lane, C.R. (2017). Delineating wetland catchments and modeling hydrologic connectivity using LiDAR data and aerial imagery. Hydrology and Earth System Sciences . 21: 3579-3595. DOI: 10.5194/hess-21-3579-2017 Wu, Q. , Deng, C., & Chen, Z. (2016). Automated delineation of karst sinkholes from LiDAR-derived digital elevation models. Geomorphology . 266: 1-10. DOI: 10.1016/j.geomorph.2016.05.006 Wu, Q. , Su, H., Sherman, D.J., Liu, H., Wozencraft, J.M., Yu, B., & Chen, Z. (2016). A graph-based approach for assessing storm-induced coastal changes. International Journal of Remote Sensing . 37:4854-4873. DOI: 10.1080/01431161.2016.1225180 Wu, Q. , & Lane, C.R. (2016). Delineation and quantification of wetland depressions in the Prairie Pothole Region of North Dakota. Wetlands . 36(2):215\u2013227. DOI: 10.1007/s13157-015-0731-6 Wu, Q. , Liu, H., Wang, S., Yu, B., Beck, R., & Hinkel, K. (2015). A localized contour tree method for deriving geometric and topological properties of complex surface depressions based on high-resolution topographic data. International Journal of Geographical Information Science . 29(12): 2041-2060. DOI: 10.1080/13658816.2015.1038719 Wu, Q. , Lane, C.R., & Liu, H. (2014). An effective method for detecting potential woodland vernal pools using high-resolution LiDAR data and aerial imagery. Remote Sensing . 6(11):11444-11467. DOI: 10.3390/rs61111444","title":"Citations"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/giswqs/lidar/issues . If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 lidar could always use more documentation, whether as part of the official lidar docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/giswqs/lidar/issues . If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome. Get Started \u00b6 Ready to contribute? Here's how to set up lidar for local development. Fork the lidar repo on GitHub. Clone your fork locally: 1 git clone git@github.com:your_name_here/lidar.git Install your local copy into a conda env. Assuming you have conda installed, this is how you set up your fork for local development: 1 2 3 4 conda create -n lidar-test python conda activate lidar-test cd lidar/ pip install -e . Create a branch for local development: 1 git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass flake8 and the tests, including testing other Python versions with tox: 1 2 flake8 lidar tests python setup.py test or pytest To get flake8 and tox, just pip install them into your conda env. Commit your changes and push your branch to GitHub: 1 2 3 git add . git commit -m \"Your detailed description of your changes.\" git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.7 and 3.8. Check https://github.com/giswqs/lidar/actions and make sure that the tests pass for all supported Python versions.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/giswqs/lidar/issues . If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"lidar could always use more documentation, whether as part of the official lidar docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/giswqs/lidar/issues . If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome.","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up lidar for local development. Fork the lidar repo on GitHub. Clone your fork locally: 1 git clone git@github.com:your_name_here/lidar.git Install your local copy into a conda env. Assuming you have conda installed, this is how you set up your fork for local development: 1 2 3 4 conda create -n lidar-test python conda activate lidar-test cd lidar/ pip install -e . Create a branch for local development: 1 git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass flake8 and the tests, including testing other Python versions with tox: 1 2 flake8 lidar tests python setup.py test or pytest To get flake8 and tox, just pip install them into your conda env. Commit your changes and push your branch to GitHub: 1 2 3 git add . git commit -m \"Your detailed description of your changes.\" git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.7 and 3.8. Check https://github.com/giswqs/lidar/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"filling/","text":"filling module \u00b6 Module for filling surface depressions. Depression \u00b6 The class for storing depression info. ExtractSinks ( in_dem , min_size , out_dir ) \u00b6 Extract sinks (e.g., maximum depression extent) from a DEM. Parameters: Name Type Description Default in_dem str File path to the input DEM. required min_size int The minimum number of pixels to be considered as a sink. required out_dir str File path to the output directory. required Returns: Type Description object The richDEM array containing sinks. Source code in lidar/filling.py def ExtractSinks ( in_dem , min_size , out_dir ): \"\"\"Extract sinks (e.g., maximum depression extent) from a DEM. Args: in_dem (str): File path to the input DEM. min_size (int): The minimum number of pixels to be considered as a sink. out_dir (str): File path to the output directory. Returns: object: The richDEM array containing sinks. \"\"\" start_time = time . time () out_dem = os . path . join ( out_dir , \"dem.tif\" ) out_dem_filled = os . path . join ( out_dir , \"dem_filled.tif\" ) out_dem_diff = os . path . join ( out_dir , \"dem_diff.tif\" ) out_sink = os . path . join ( out_dir , \"sink.tif\" ) out_region = os . path . join ( out_dir , \"region.tif\" ) out_depth = os . path . join ( out_dir , \"depth.tif\" ) out_csv_file = os . path . join ( out_dir , \"regions_info.csv\" ) out_vec_file = os . path . join ( out_dir , \"regions.shp\" ) # create output folder if nonexistent if not os . path . exists ( out_dir ): os . mkdir ( out_dir ) # load the dem and get dem info print ( \"Loading data ...\" ) dem = rd . LoadGDAL ( in_dem ) no_data = dem . no_data projection = dem . projection geotransform = dem . geotransform cell_size = np . round ( geotransform [ 1 ], decimals = 2 ) # get min and max elevation of the dem max_elev = np . float ( np . max ( dem )) min_elev = np . float ( np . min ( dem [ dem > 0 ])) print ( \"min = {:.2f} , max = {:.2f} , no_data = {} , cell_size = {} \" . format ( min_elev , max_elev , no_data , cell_size ) ) # depression filling print ( \"Depression filling ...\" ) dem_filled = rd . FillDepressions ( dem , in_place = False ) dem_diff = dem_filled - dem dem_diff . no_data = 0 print ( \"Saving filled dem ...\" ) rd . SaveGDAL ( out_dem_filled , dem_filled ) rd . SaveGDAL ( out_dem_diff , dem_diff ) # nb_labels is the total number of objects. 0 represents background object. print ( \"Region grouping ...\" ) label_objects , nb_labels = regionGroup ( dem_diff , min_size , no_data ) dem_diff [ label_objects == 0 ] = 0 depth = np2rdarray ( dem_diff , no_data = 0 , projection = projection , geotransform = geotransform ) rd . SaveGDAL ( out_depth , depth ) del dem_diff , depth print ( \"Computing properties ...\" ) # objects = measure.regionprops(label_objects, dem, coordinates='xy') objects = measure . regionprops ( label_objects , dem ) dep_list = get_dep_props ( objects , cell_size ) write_dep_csv ( dep_list , out_csv_file ) del objects , dep_list # convert numpy to richdem data format region = np2rdarray ( label_objects , no_data = 0 , projection = projection , geotransform = geotransform ) del label_objects print ( \"Saving sink dem ...\" ) sink = np . copy ( dem ) sink [ region == 0 ] = 0 sink = np2rdarray ( sink , no_data = 0 , projection = projection , geotransform = geotransform ) rd . SaveGDAL ( out_sink , sink ) # del sink print ( \"Saving refined dem ...\" ) dem_refined = dem_filled dem_refined [ region > 0 ] = dem [ region > 0 ] dem_refined = np2rdarray ( dem_refined , no_data = no_data , projection = projection , geotransform = geotransform ) rd . SaveGDAL ( out_dem , dem_refined ) rd . SaveGDAL ( out_region , region ) del dem_refined , region , dem print ( \"Converting raster to vector ...\" ) polygonize ( out_region , out_vec_file ) end_time = time . time () print ( \"Total run time: \\t\\t\\t {:.4f} s \\n \" . format ( end_time - start_time )) return out_sink get_dep_props ( objects , resolution ) \u00b6 Computes depression attributes. Parameters: Name Type Description Default objects object The labeled objects. required resolution float The spatial reoslution of the image. required Returns: Type Description list A list of depression objects with attributes. Source code in lidar/filling.py def get_dep_props ( objects , resolution ): \"\"\"Computes depression attributes. Args: objects (object): The labeled objects. resolution (float): The spatial reoslution of the image. Returns: list: A list of depression objects with attributes. \"\"\" dep_list = [] for object in objects : unique_id = object . label count = object . area size = count * pow ( resolution , 2 ) # depression size min_elev = np . float ( object . min_intensity ) # depression min elevation max_elev = np . float ( object . max_intensity ) # depression max elevation max_depth = max_elev - min_elev # depression max depth mean_depth = np . float ( ( max_elev * count - np . sum ( object . intensity_image )) / count ) # depression mean depth volume = mean_depth * count * pow ( resolution , 2 ) # depression volume perimeter = object . perimeter * resolution major_axis = object . major_axis_length * resolution minor_axis = object . minor_axis_length * resolution if minor_axis == 0 : minor_axis = resolution elongatedness = major_axis * 1.0 / minor_axis eccentricity = object . eccentricity orientation = object . orientation / 3.1415 * 180 area_bbox_ratio = object . extent dep_list . append ( Depression ( unique_id , count , size , volume , mean_depth , max_depth , min_elev , max_elev , perimeter , major_axis , minor_axis , elongatedness , eccentricity , orientation , area_bbox_ratio , ) ) return dep_list np2rdarray ( in_array , no_data , projection , geotransform ) \u00b6 Converts an numpy array to rdarray. Parameters: Name Type Description Default in_array np.array The input numpy array. required no_data float The no_data value of the array. required projection str The projection of the image. required geotransform str The geotransform of the image. required Returns: Type Description object The richDEM array. Source code in lidar/filling.py def np2rdarray ( in_array , no_data , projection , geotransform ): \"\"\"Converts an numpy array to rdarray. Args: in_array (np.array): The input numpy array. no_data (float): The no_data value of the array. projection (str): The projection of the image. geotransform (str): The geotransform of the image. Returns: object: The richDEM array. \"\"\" out_array = rd . rdarray ( in_array , no_data = no_data ) out_array . projection = projection out_array . geotransform = geotransform return out_array polygonize ( img , shp_path ) \u00b6 Converts a raster image to vector. Parameters: Name Type Description Default img str File path to the input image. required shp_path str File path to the output shapefile. required Source code in lidar/filling.py def polygonize ( img , shp_path ): \"\"\"Converts a raster image to vector. Args: img (str): File path to the input image. shp_path (str): File path to the output shapefile. \"\"\" # mapping between gdal type and ogr field type type_mapping = { gdal . GDT_Byte : ogr . OFTInteger , gdal . GDT_UInt16 : ogr . OFTInteger , gdal . GDT_Int16 : ogr . OFTInteger , gdal . GDT_UInt32 : ogr . OFTInteger , gdal . GDT_Int32 : ogr . OFTInteger , gdal . GDT_Float32 : ogr . OFTReal , gdal . GDT_Float64 : ogr . OFTReal , gdal . GDT_CInt16 : ogr . OFTInteger , gdal . GDT_CInt32 : ogr . OFTInteger , gdal . GDT_CFloat32 : ogr . OFTReal , gdal . GDT_CFloat64 : ogr . OFTReal , } ds = gdal . Open ( img ) prj = ds . GetProjection () srcband = ds . GetRasterBand ( 1 ) dst_layername = \"Shape\" drv = ogr . GetDriverByName ( \"ESRI Shapefile\" ) dst_ds = drv . CreateDataSource ( shp_path ) srs = osr . SpatialReference ( wkt = prj ) dst_layer = dst_ds . CreateLayer ( dst_layername , srs = srs ) # raster_field = ogr.FieldDefn('id', type_mapping[srcband.DataType]) raster_field = ogr . FieldDefn ( \"id\" , type_mapping [ gdal . GDT_Int32 ]) dst_layer . CreateField ( raster_field ) gdal . Polygonize ( srcband , srcband , dst_layer , 0 , [], callback = None ) del img , ds , srcband , dst_ds , dst_layer regionGroup ( img_array , min_size , no_data ) \u00b6 IdentifIies regions based on region growing method Parameters: Name Type Description Default img_array np.array The numpy array containing the image. required min_size int The minimum number of pixels to be considered as a depression. required no_data float The no_data value of the image. required Returns: Type Description tuple The labelled objects and total number of labels. Source code in lidar/filling.py def regionGroup ( img_array , min_size , no_data ): \"\"\"IdentifIies regions based on region growing method Args: img_array (np.array): The numpy array containing the image. min_size (int): The minimum number of pixels to be considered as a depression. no_data (float): The no_data value of the image. Returns: tuple: The labelled objects and total number of labels. \"\"\" img_array [ img_array == no_data ] = 0 label_objects , nb_labels = ndimage . label ( img_array ) sizes = np . bincount ( label_objects . ravel ()) mask_sizes = sizes > min_size mask_sizes [ 0 ] = 0 image_cleaned = mask_sizes [ label_objects ] label_objects , nb_labels = ndimage . label ( image_cleaned ) # nb_labels is the total number of objects. 0 represents background object. return label_objects , nb_labels write_dep_csv ( dep_list , csv_file ) \u00b6 Saves the depression list info to a CSV file. Parameters: Name Type Description Default dep_list list A list of depression objects with attributes. required csv_file str File path to the output CSV file. required Source code in lidar/filling.py def write_dep_csv ( dep_list , csv_file ): \"\"\"Saves the depression list info to a CSV file. Args: dep_list (list): A list of depression objects with attributes. csv_file (str): File path to the output CSV file. \"\"\" csv = open ( csv_file , \"w\" ) header = ( \"region-id\" + \",\" + \"count\" + \",\" + \"area\" + \",\" + \"volume\" + \",\" + \"avg-depth\" + \",\" + \"max-depth\" + \",\" + \"min-elev\" + \",\" + \"max-elev\" + \",\" + \"perimeter\" + \",\" + \"major-axis\" + \",\" + \"minor-axis\" + \",\" + \"elongatedness\" + \",\" + \"eccentricity\" + \",\" + \"orientation\" + \",\" + \"area-bbox-ratio\" ) csv . write ( header + \" \\n \" ) for dep in dep_list : line = \" {} , {} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} \" . format ( dep . id , dep . count , dep . size , dep . volume , dep . meanDepth , dep . maxDepth , dep . minElev , dep . bndElev , dep . perimeter , dep . major_axis , dep . minor_axis , dep . elongatedness , dep . eccentricity , dep . orientation , dep . area_bbox_ratio , ) csv . write ( line + \" \\n \" ) csv . close ()","title":"filling module"},{"location":"filling/#filling-module","text":"Module for filling surface depressions.","title":"filling module"},{"location":"filling/#lidar.filling.Depression","text":"The class for storing depression info.","title":"Depression"},{"location":"filling/#lidar.filling.ExtractSinks","text":"Extract sinks (e.g., maximum depression extent) from a DEM. Parameters: Name Type Description Default in_dem str File path to the input DEM. required min_size int The minimum number of pixels to be considered as a sink. required out_dir str File path to the output directory. required Returns: Type Description object The richDEM array containing sinks. Source code in lidar/filling.py def ExtractSinks ( in_dem , min_size , out_dir ): \"\"\"Extract sinks (e.g., maximum depression extent) from a DEM. Args: in_dem (str): File path to the input DEM. min_size (int): The minimum number of pixels to be considered as a sink. out_dir (str): File path to the output directory. Returns: object: The richDEM array containing sinks. \"\"\" start_time = time . time () out_dem = os . path . join ( out_dir , \"dem.tif\" ) out_dem_filled = os . path . join ( out_dir , \"dem_filled.tif\" ) out_dem_diff = os . path . join ( out_dir , \"dem_diff.tif\" ) out_sink = os . path . join ( out_dir , \"sink.tif\" ) out_region = os . path . join ( out_dir , \"region.tif\" ) out_depth = os . path . join ( out_dir , \"depth.tif\" ) out_csv_file = os . path . join ( out_dir , \"regions_info.csv\" ) out_vec_file = os . path . join ( out_dir , \"regions.shp\" ) # create output folder if nonexistent if not os . path . exists ( out_dir ): os . mkdir ( out_dir ) # load the dem and get dem info print ( \"Loading data ...\" ) dem = rd . LoadGDAL ( in_dem ) no_data = dem . no_data projection = dem . projection geotransform = dem . geotransform cell_size = np . round ( geotransform [ 1 ], decimals = 2 ) # get min and max elevation of the dem max_elev = np . float ( np . max ( dem )) min_elev = np . float ( np . min ( dem [ dem > 0 ])) print ( \"min = {:.2f} , max = {:.2f} , no_data = {} , cell_size = {} \" . format ( min_elev , max_elev , no_data , cell_size ) ) # depression filling print ( \"Depression filling ...\" ) dem_filled = rd . FillDepressions ( dem , in_place = False ) dem_diff = dem_filled - dem dem_diff . no_data = 0 print ( \"Saving filled dem ...\" ) rd . SaveGDAL ( out_dem_filled , dem_filled ) rd . SaveGDAL ( out_dem_diff , dem_diff ) # nb_labels is the total number of objects. 0 represents background object. print ( \"Region grouping ...\" ) label_objects , nb_labels = regionGroup ( dem_diff , min_size , no_data ) dem_diff [ label_objects == 0 ] = 0 depth = np2rdarray ( dem_diff , no_data = 0 , projection = projection , geotransform = geotransform ) rd . SaveGDAL ( out_depth , depth ) del dem_diff , depth print ( \"Computing properties ...\" ) # objects = measure.regionprops(label_objects, dem, coordinates='xy') objects = measure . regionprops ( label_objects , dem ) dep_list = get_dep_props ( objects , cell_size ) write_dep_csv ( dep_list , out_csv_file ) del objects , dep_list # convert numpy to richdem data format region = np2rdarray ( label_objects , no_data = 0 , projection = projection , geotransform = geotransform ) del label_objects print ( \"Saving sink dem ...\" ) sink = np . copy ( dem ) sink [ region == 0 ] = 0 sink = np2rdarray ( sink , no_data = 0 , projection = projection , geotransform = geotransform ) rd . SaveGDAL ( out_sink , sink ) # del sink print ( \"Saving refined dem ...\" ) dem_refined = dem_filled dem_refined [ region > 0 ] = dem [ region > 0 ] dem_refined = np2rdarray ( dem_refined , no_data = no_data , projection = projection , geotransform = geotransform ) rd . SaveGDAL ( out_dem , dem_refined ) rd . SaveGDAL ( out_region , region ) del dem_refined , region , dem print ( \"Converting raster to vector ...\" ) polygonize ( out_region , out_vec_file ) end_time = time . time () print ( \"Total run time: \\t\\t\\t {:.4f} s \\n \" . format ( end_time - start_time )) return out_sink","title":"ExtractSinks()"},{"location":"filling/#lidar.filling.get_dep_props","text":"Computes depression attributes. Parameters: Name Type Description Default objects object The labeled objects. required resolution float The spatial reoslution of the image. required Returns: Type Description list A list of depression objects with attributes. Source code in lidar/filling.py def get_dep_props ( objects , resolution ): \"\"\"Computes depression attributes. Args: objects (object): The labeled objects. resolution (float): The spatial reoslution of the image. Returns: list: A list of depression objects with attributes. \"\"\" dep_list = [] for object in objects : unique_id = object . label count = object . area size = count * pow ( resolution , 2 ) # depression size min_elev = np . float ( object . min_intensity ) # depression min elevation max_elev = np . float ( object . max_intensity ) # depression max elevation max_depth = max_elev - min_elev # depression max depth mean_depth = np . float ( ( max_elev * count - np . sum ( object . intensity_image )) / count ) # depression mean depth volume = mean_depth * count * pow ( resolution , 2 ) # depression volume perimeter = object . perimeter * resolution major_axis = object . major_axis_length * resolution minor_axis = object . minor_axis_length * resolution if minor_axis == 0 : minor_axis = resolution elongatedness = major_axis * 1.0 / minor_axis eccentricity = object . eccentricity orientation = object . orientation / 3.1415 * 180 area_bbox_ratio = object . extent dep_list . append ( Depression ( unique_id , count , size , volume , mean_depth , max_depth , min_elev , max_elev , perimeter , major_axis , minor_axis , elongatedness , eccentricity , orientation , area_bbox_ratio , ) ) return dep_list","title":"get_dep_props()"},{"location":"filling/#lidar.filling.np2rdarray","text":"Converts an numpy array to rdarray. Parameters: Name Type Description Default in_array np.array The input numpy array. required no_data float The no_data value of the array. required projection str The projection of the image. required geotransform str The geotransform of the image. required Returns: Type Description object The richDEM array. Source code in lidar/filling.py def np2rdarray ( in_array , no_data , projection , geotransform ): \"\"\"Converts an numpy array to rdarray. Args: in_array (np.array): The input numpy array. no_data (float): The no_data value of the array. projection (str): The projection of the image. geotransform (str): The geotransform of the image. Returns: object: The richDEM array. \"\"\" out_array = rd . rdarray ( in_array , no_data = no_data ) out_array . projection = projection out_array . geotransform = geotransform return out_array","title":"np2rdarray()"},{"location":"filling/#lidar.filling.polygonize","text":"Converts a raster image to vector. Parameters: Name Type Description Default img str File path to the input image. required shp_path str File path to the output shapefile. required Source code in lidar/filling.py def polygonize ( img , shp_path ): \"\"\"Converts a raster image to vector. Args: img (str): File path to the input image. shp_path (str): File path to the output shapefile. \"\"\" # mapping between gdal type and ogr field type type_mapping = { gdal . GDT_Byte : ogr . OFTInteger , gdal . GDT_UInt16 : ogr . OFTInteger , gdal . GDT_Int16 : ogr . OFTInteger , gdal . GDT_UInt32 : ogr . OFTInteger , gdal . GDT_Int32 : ogr . OFTInteger , gdal . GDT_Float32 : ogr . OFTReal , gdal . GDT_Float64 : ogr . OFTReal , gdal . GDT_CInt16 : ogr . OFTInteger , gdal . GDT_CInt32 : ogr . OFTInteger , gdal . GDT_CFloat32 : ogr . OFTReal , gdal . GDT_CFloat64 : ogr . OFTReal , } ds = gdal . Open ( img ) prj = ds . GetProjection () srcband = ds . GetRasterBand ( 1 ) dst_layername = \"Shape\" drv = ogr . GetDriverByName ( \"ESRI Shapefile\" ) dst_ds = drv . CreateDataSource ( shp_path ) srs = osr . SpatialReference ( wkt = prj ) dst_layer = dst_ds . CreateLayer ( dst_layername , srs = srs ) # raster_field = ogr.FieldDefn('id', type_mapping[srcband.DataType]) raster_field = ogr . FieldDefn ( \"id\" , type_mapping [ gdal . GDT_Int32 ]) dst_layer . CreateField ( raster_field ) gdal . Polygonize ( srcband , srcband , dst_layer , 0 , [], callback = None ) del img , ds , srcband , dst_ds , dst_layer","title":"polygonize()"},{"location":"filling/#lidar.filling.regionGroup","text":"IdentifIies regions based on region growing method Parameters: Name Type Description Default img_array np.array The numpy array containing the image. required min_size int The minimum number of pixels to be considered as a depression. required no_data float The no_data value of the image. required Returns: Type Description tuple The labelled objects and total number of labels. Source code in lidar/filling.py def regionGroup ( img_array , min_size , no_data ): \"\"\"IdentifIies regions based on region growing method Args: img_array (np.array): The numpy array containing the image. min_size (int): The minimum number of pixels to be considered as a depression. no_data (float): The no_data value of the image. Returns: tuple: The labelled objects and total number of labels. \"\"\" img_array [ img_array == no_data ] = 0 label_objects , nb_labels = ndimage . label ( img_array ) sizes = np . bincount ( label_objects . ravel ()) mask_sizes = sizes > min_size mask_sizes [ 0 ] = 0 image_cleaned = mask_sizes [ label_objects ] label_objects , nb_labels = ndimage . label ( image_cleaned ) # nb_labels is the total number of objects. 0 represents background object. return label_objects , nb_labels","title":"regionGroup()"},{"location":"filling/#lidar.filling.write_dep_csv","text":"Saves the depression list info to a CSV file. Parameters: Name Type Description Default dep_list list A list of depression objects with attributes. required csv_file str File path to the output CSV file. required Source code in lidar/filling.py def write_dep_csv ( dep_list , csv_file ): \"\"\"Saves the depression list info to a CSV file. Args: dep_list (list): A list of depression objects with attributes. csv_file (str): File path to the output CSV file. \"\"\" csv = open ( csv_file , \"w\" ) header = ( \"region-id\" + \",\" + \"count\" + \",\" + \"area\" + \",\" + \"volume\" + \",\" + \"avg-depth\" + \",\" + \"max-depth\" + \",\" + \"min-elev\" + \",\" + \"max-elev\" + \",\" + \"perimeter\" + \",\" + \"major-axis\" + \",\" + \"minor-axis\" + \",\" + \"elongatedness\" + \",\" + \"eccentricity\" + \",\" + \"orientation\" + \",\" + \"area-bbox-ratio\" ) csv . write ( header + \" \\n \" ) for dep in dep_list : line = \" {} , {} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} \" . format ( dep . id , dep . count , dep . size , dep . volume , dep . meanDepth , dep . maxDepth , dep . minElev , dep . bndElev , dep . perimeter , dep . major_axis , dep . minor_axis , dep . elongatedness , dep . eccentricity , dep . orientation , dep . area_bbox_ratio , ) csv . write ( line + \" \\n \" ) csv . close ()","title":"write_dep_csv()"},{"location":"filtering/","text":"filtering module \u00b6 Module for applying filters to image. GaussianFilter ( in_dem , sigma = 1 , out_file = None ) \u00b6 Applies a Gaussian filter to an image. Parameters: Name Type Description Default in_dem str File path to the input image. required sigma int Standard deviation. Defaults to 1. 1 out_file str File path to the output image. Defaults to None. None Returns: Type Description np.array The numpy array containing the filtered image. Source code in lidar/filtering.py def GaussianFilter ( in_dem , sigma = 1 , out_file = None ): \"\"\"Applies a Gaussian filter to an image. Args: in_dem (str): File path to the input image. sigma (int, optional): Standard deviation. Defaults to 1. out_file (str, optional): File path to the output image. Defaults to None. Returns: np.array: The numpy array containing the filtered image. \"\"\" print ( \"Gaussian filtering ...\" ) start_time = time . time () dem = rd . LoadGDAL ( in_dem ) no_data = dem . no_data projection = dem . projection geotransform = dem . geotransform gau = ndimage . gaussian_filter ( dem , sigma = sigma ) gau = np2rdarray ( gau , no_data , projection , geotransform ) print ( \"Run time: {:.4f} seconds\" . format ( time . time () - start_time )) if out_file is not None : print ( \"Saving dem ...\" ) rd . SaveGDAL ( out_file , gau ) return out_file return gau MeanFilter ( in_dem , kernel_size = 3 , out_file = None ) \u00b6 Applies a mean filter to an image. Parameters: Name Type Description Default in_dem str File path to the input image. required kernel_size int The size of the moving window. Defaults to 3. 3 out_file str File path to the output image. Defaults to None. None Returns: Type Description np.array The numpy array containing the filtered image. Source code in lidar/filtering.py def MeanFilter ( in_dem , kernel_size = 3 , out_file = None ): \"\"\"Applies a mean filter to an image. Args: in_dem (str): File path to the input image. kernel_size (int, optional): The size of the moving window. Defaults to 3. out_file (str, optional): File path to the output image. Defaults to None. Returns: np.array: The numpy array containing the filtered image. \"\"\" print ( \"Mean filtering ...\" ) start_time = time . time () dem = rd . LoadGDAL ( in_dem ) no_data = dem . no_data projection = dem . projection geotransform = dem . geotransform weights = np . full (( kernel_size , kernel_size ), 1.0 / ( kernel_size * kernel_size )) mean = ndimage . filters . convolve ( dem , weights ) mean = np2rdarray ( mean , no_data , projection , geotransform ) print ( \"Run time: {:.4f} seconds\" . format ( time . time () - start_time )) if out_file is not None : print ( \"Saving dem ...\" ) rd . SaveGDAL ( out_file , mean ) return out_file return mean MedianFilter ( in_dem , kernel_size = 3 , out_file = None ) \u00b6 Applies a median filter to an image. Parameters: Name Type Description Default in_dem str File path to the input image. required kernel_size int The size of the moving window. Defaults to 3. 3 out_file str File path to the output image. Defaults to None. None Returns: Type Description np.array The numpy array containing the filtered image. Source code in lidar/filtering.py def MedianFilter ( in_dem , kernel_size = 3 , out_file = None ): \"\"\"Applies a median filter to an image. Args: in_dem (str): File path to the input image. kernel_size (int, optional): The size of the moving window. Defaults to 3. out_file (str, optional): File path to the output image. Defaults to None. Returns: np.array: The numpy array containing the filtered image. \"\"\" print ( \"Median filtering ...\" ) start_time = time . time () dem = rd . LoadGDAL ( in_dem ) no_data = dem . no_data projection = dem . projection geotransform = dem . geotransform med = ndimage . median_filter ( dem , size = kernel_size ) med = np2rdarray ( med , no_data , projection , geotransform ) print ( \"Run time: {:.4f} seconds\" . format ( time . time () - start_time )) if out_file is not None : print ( \"Saving dem ...\" ) rd . SaveGDAL ( out_file , med ) return out_file return med np2rdarray ( in_array , no_data , projection , geotransform ) \u00b6 Converts an numpy array to rdarray. Parameters: Name Type Description Default in_array np.array The input numpy array. required no_data float The no_data value of the array. required projection str The projection of the image. required geotransform str The geotransform of the image. required Returns: Type Description object The richDEM array. Source code in lidar/filtering.py def np2rdarray ( in_array , no_data , projection , geotransform ): \"\"\"Converts an numpy array to rdarray. Args: in_array (np.array): The input numpy array. no_data (float): The no_data value of the array. projection (str): The projection of the image. geotransform (str): The geotransform of the image. Returns: object: The richDEM array. \"\"\" out_array = rd . rdarray ( in_array , no_data = no_data ) out_array . projection = projection out_array . geotransform = geotransform return out_array","title":"filtering module"},{"location":"filtering/#filtering-module","text":"Module for applying filters to image.","title":"filtering module"},{"location":"filtering/#lidar.filtering.GaussianFilter","text":"Applies a Gaussian filter to an image. Parameters: Name Type Description Default in_dem str File path to the input image. required sigma int Standard deviation. Defaults to 1. 1 out_file str File path to the output image. Defaults to None. None Returns: Type Description np.array The numpy array containing the filtered image. Source code in lidar/filtering.py def GaussianFilter ( in_dem , sigma = 1 , out_file = None ): \"\"\"Applies a Gaussian filter to an image. Args: in_dem (str): File path to the input image. sigma (int, optional): Standard deviation. Defaults to 1. out_file (str, optional): File path to the output image. Defaults to None. Returns: np.array: The numpy array containing the filtered image. \"\"\" print ( \"Gaussian filtering ...\" ) start_time = time . time () dem = rd . LoadGDAL ( in_dem ) no_data = dem . no_data projection = dem . projection geotransform = dem . geotransform gau = ndimage . gaussian_filter ( dem , sigma = sigma ) gau = np2rdarray ( gau , no_data , projection , geotransform ) print ( \"Run time: {:.4f} seconds\" . format ( time . time () - start_time )) if out_file is not None : print ( \"Saving dem ...\" ) rd . SaveGDAL ( out_file , gau ) return out_file return gau","title":"GaussianFilter()"},{"location":"filtering/#lidar.filtering.MeanFilter","text":"Applies a mean filter to an image. Parameters: Name Type Description Default in_dem str File path to the input image. required kernel_size int The size of the moving window. Defaults to 3. 3 out_file str File path to the output image. Defaults to None. None Returns: Type Description np.array The numpy array containing the filtered image. Source code in lidar/filtering.py def MeanFilter ( in_dem , kernel_size = 3 , out_file = None ): \"\"\"Applies a mean filter to an image. Args: in_dem (str): File path to the input image. kernel_size (int, optional): The size of the moving window. Defaults to 3. out_file (str, optional): File path to the output image. Defaults to None. Returns: np.array: The numpy array containing the filtered image. \"\"\" print ( \"Mean filtering ...\" ) start_time = time . time () dem = rd . LoadGDAL ( in_dem ) no_data = dem . no_data projection = dem . projection geotransform = dem . geotransform weights = np . full (( kernel_size , kernel_size ), 1.0 / ( kernel_size * kernel_size )) mean = ndimage . filters . convolve ( dem , weights ) mean = np2rdarray ( mean , no_data , projection , geotransform ) print ( \"Run time: {:.4f} seconds\" . format ( time . time () - start_time )) if out_file is not None : print ( \"Saving dem ...\" ) rd . SaveGDAL ( out_file , mean ) return out_file return mean","title":"MeanFilter()"},{"location":"filtering/#lidar.filtering.MedianFilter","text":"Applies a median filter to an image. Parameters: Name Type Description Default in_dem str File path to the input image. required kernel_size int The size of the moving window. Defaults to 3. 3 out_file str File path to the output image. Defaults to None. None Returns: Type Description np.array The numpy array containing the filtered image. Source code in lidar/filtering.py def MedianFilter ( in_dem , kernel_size = 3 , out_file = None ): \"\"\"Applies a median filter to an image. Args: in_dem (str): File path to the input image. kernel_size (int, optional): The size of the moving window. Defaults to 3. out_file (str, optional): File path to the output image. Defaults to None. Returns: np.array: The numpy array containing the filtered image. \"\"\" print ( \"Median filtering ...\" ) start_time = time . time () dem = rd . LoadGDAL ( in_dem ) no_data = dem . no_data projection = dem . projection geotransform = dem . geotransform med = ndimage . median_filter ( dem , size = kernel_size ) med = np2rdarray ( med , no_data , projection , geotransform ) print ( \"Run time: {:.4f} seconds\" . format ( time . time () - start_time )) if out_file is not None : print ( \"Saving dem ...\" ) rd . SaveGDAL ( out_file , med ) return out_file return med","title":"MedianFilter()"},{"location":"filtering/#lidar.filtering.np2rdarray","text":"Converts an numpy array to rdarray. Parameters: Name Type Description Default in_array np.array The input numpy array. required no_data float The no_data value of the array. required projection str The projection of the image. required geotransform str The geotransform of the image. required Returns: Type Description object The richDEM array. Source code in lidar/filtering.py def np2rdarray ( in_array , no_data , projection , geotransform ): \"\"\"Converts an numpy array to rdarray. Args: in_array (np.array): The input numpy array. no_data (float): The no_data value of the array. projection (str): The projection of the image. geotransform (str): The geotransform of the image. Returns: object: The richDEM array. \"\"\" out_array = rd . rdarray ( in_array , no_data = no_data ) out_array . projection = projection out_array . geotransform = geotransform return out_array","title":"np2rdarray()"},{"location":"get-started/","text":"Launch the interactive notebook tutorial for the lidar Python package with Google Colab now: A Quick Example \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import os import pkg_resources from lidar import * # identify the sample data directory of the package package_name = 'lidar' data_dir = pkg_resources . resource_filename ( package_name , 'data/' ) # use the sample dem. Change it to your own dem if needed in_dem = os . path . join ( data_dir , 'dem.tif' ) # set the output directory out_dir = os . getcwd () # parameters for identifying sinks and delineating nested depressions min_size = 1000 # minimum number of pixels as a depression min_depth = 0.5 # minimum depth as a depression interval = 0.3 # slicing interval for the level-set method bool_shp = True # output shapefiles for each individual level # extracting sinks based on user-defined minimum depression size out_dem = os . path . join ( out_dir , \"median.tif\" ) in_dem = MedianFilter ( in_dem , kernel_size = 3 , out_file = out_dem ) sink_path = ExtractSinks ( in_dem , min_size , out_dir ) dep_id_path , dep_level_path = DelineateDepressions ( sink_path , min_size , min_depth , interval , out_dir , bool_shp ) print ( 'Results are saved in: {} ' . format ( out_dir )) lidar GUI \u00b6 lidar also provides a Graphical User Interface (GUI), which can be invoked using the following Python script: 1 2 import lidar lidar . gui () ArcGIS Toolbox \u00b6 Toolbox interface \u00b6 Video tutorials \u00b6 Delineating nested surface depressions and catchments using ArcGIS Pro Delineating nested surface depressions and catchments using ArcMap","title":"Get Started"},{"location":"get-started/#a-quick-example","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import os import pkg_resources from lidar import * # identify the sample data directory of the package package_name = 'lidar' data_dir = pkg_resources . resource_filename ( package_name , 'data/' ) # use the sample dem. Change it to your own dem if needed in_dem = os . path . join ( data_dir , 'dem.tif' ) # set the output directory out_dir = os . getcwd () # parameters for identifying sinks and delineating nested depressions min_size = 1000 # minimum number of pixels as a depression min_depth = 0.5 # minimum depth as a depression interval = 0.3 # slicing interval for the level-set method bool_shp = True # output shapefiles for each individual level # extracting sinks based on user-defined minimum depression size out_dem = os . path . join ( out_dir , \"median.tif\" ) in_dem = MedianFilter ( in_dem , kernel_size = 3 , out_file = out_dem ) sink_path = ExtractSinks ( in_dem , min_size , out_dir ) dep_id_path , dep_level_path = DelineateDepressions ( sink_path , min_size , min_depth , interval , out_dir , bool_shp ) print ( 'Results are saved in: {} ' . format ( out_dir ))","title":"A Quick Example"},{"location":"get-started/#lidar-gui","text":"lidar also provides a Graphical User Interface (GUI), which can be invoked using the following Python script: 1 2 import lidar lidar . gui ()","title":"lidar GUI"},{"location":"get-started/#arcgis-toolbox","text":"","title":"ArcGIS Toolbox"},{"location":"get-started/#toolbox-interface","text":"","title":"Toolbox interface"},{"location":"get-started/#video-tutorials","text":"Delineating nested surface depressions and catchments using ArcGIS Pro Delineating nested surface depressions and catchments using ArcMap","title":"Video tutorials"},{"location":"installation/","text":"Installation \u00b6 lidar supports a variety of platforms, including Microsoft Windows, macOS, and Linux operating systems. Note that you will need to have Python 3.x (< 3.9) installed. Python 2.x is not supported. lidar is available on both PyPI and conda-forge . lidar has a GDAL dependency, which can be challenging to install using pip on Windows. Therefore, it is highly recommended to install lidar from the conda-forge channel. If you encounter any errors, please check the Dependencies section below. Install from PyPI \u00b6 To install lidar from PyPI, run this command in your terminal: 1 pip install lidar Install from conda-forage \u00b6 If you have Anaconda or Miniconda installed on your computer, you can create a fresh conda environment to install lidar: 1 2 3 conda create -n py38 python=3.8 conda activate py38 conda install lidar -c conda-forge Upgrade lidar \u00b6 If you have installed lidar before and want to upgrade to the latest version, you can run the following command in your terminal: 1 pip install -U lidar If you use conda, you can update lidar to the latest version by running the following command in your terminal: 1 conda update lidar -c conda-forge To install the development version from GitHub directly using Git, run the following code: 1 pip install git+https://github.com/giswqs/lidar Dependencies \u00b6 lidar's Python dependencies are listed in its requirements.txt file. In addition, lidar has a C library dependency: GDAL >=1.11.2. How to install GDAL in different operating systems will be explained below. More informaton about GDAL can be found here . Linux \u00b6 Debian-based Linux \u00b6 The following commands can be used to install GDAL for Debian-based Linux distributions (e.g., Ubuntu, Linux Mint). 1 2 3 sudo add-apt-repository ppa:ubuntugis/ppa sudo apt-get update sudo apt-get install gdal-bin libgdal-dev If you encounter any compiling errors, try the following commands. 1 2 3 sudo apt-get install --reinstall build-essential sudo apt-get install python3-dev pip install wheel Pacman-based Linux \u00b6 The following commands can be used to install GDAL for Pacman-based Linux distributions (e.g., Arch Linux, Manjaro). You might need to use sudo if you encounter permission errors. 1 2 3 sudo pacman -S yaourt --noconfirm yaourt -S gdal --noconfirm yaourt -S python-gdal --noconfirm macOS \u00b6 For a Homebrew based Python environment, do the following. 1 2 brew update brew install gdal Alternatively, you can install GDAL binaries from kyngchaos . You will then need to add the installed location /Library/Frameworks/GDAL.framework/Programs to your system path. Windows \u00b6 The instruction below assumes that you have installed Anaconda . Open Anaconda Prompt and enter the following commands to create a conda environment and install required packages 1 2 3 conda create -n py38 python=3.8 conda activate py38 conda install lidar -c conda-forge When installing the lidar package, if you encounter an error saying Microsoft Visual C++ 14.0 is required , please follow the steps below to fix the error and reinstall lidar . More infomration can be found at this link Fix Python 3 on Windows error - Microsoft Visual C++ 14.0 is required . Download Microsoft Build Tools for Visual Studio 2017 Double click to install the downloaded installer - Microsoft Build Tools for Visual Studio 2017 . Open Microsoft Build Tools for Visual Studio 2017 Select Workloads --> Visual C++ build tools and click the install button","title":"Installation"},{"location":"installation/#installation","text":"lidar supports a variety of platforms, including Microsoft Windows, macOS, and Linux operating systems. Note that you will need to have Python 3.x (< 3.9) installed. Python 2.x is not supported. lidar is available on both PyPI and conda-forge . lidar has a GDAL dependency, which can be challenging to install using pip on Windows. Therefore, it is highly recommended to install lidar from the conda-forge channel. If you encounter any errors, please check the Dependencies section below.","title":"Installation"},{"location":"installation/#install-from-pypi","text":"To install lidar from PyPI, run this command in your terminal: 1 pip install lidar","title":"Install from PyPI"},{"location":"installation/#install-from-conda-forage","text":"If you have Anaconda or Miniconda installed on your computer, you can create a fresh conda environment to install lidar: 1 2 3 conda create -n py38 python=3.8 conda activate py38 conda install lidar -c conda-forge","title":"Install from conda-forage"},{"location":"installation/#upgrade-lidar","text":"If you have installed lidar before and want to upgrade to the latest version, you can run the following command in your terminal: 1 pip install -U lidar If you use conda, you can update lidar to the latest version by running the following command in your terminal: 1 conda update lidar -c conda-forge To install the development version from GitHub directly using Git, run the following code: 1 pip install git+https://github.com/giswqs/lidar","title":"Upgrade lidar"},{"location":"installation/#dependencies","text":"lidar's Python dependencies are listed in its requirements.txt file. In addition, lidar has a C library dependency: GDAL >=1.11.2. How to install GDAL in different operating systems will be explained below. More informaton about GDAL can be found here .","title":"Dependencies"},{"location":"installation/#linux","text":"","title":"Linux"},{"location":"installation/#debian-based-linux","text":"The following commands can be used to install GDAL for Debian-based Linux distributions (e.g., Ubuntu, Linux Mint). 1 2 3 sudo add-apt-repository ppa:ubuntugis/ppa sudo apt-get update sudo apt-get install gdal-bin libgdal-dev If you encounter any compiling errors, try the following commands. 1 2 3 sudo apt-get install --reinstall build-essential sudo apt-get install python3-dev pip install wheel","title":"Debian-based Linux"},{"location":"installation/#pacman-based-linux","text":"The following commands can be used to install GDAL for Pacman-based Linux distributions (e.g., Arch Linux, Manjaro). You might need to use sudo if you encounter permission errors. 1 2 3 sudo pacman -S yaourt --noconfirm yaourt -S gdal --noconfirm yaourt -S python-gdal --noconfirm","title":"Pacman-based Linux"},{"location":"installation/#macos","text":"For a Homebrew based Python environment, do the following. 1 2 brew update brew install gdal Alternatively, you can install GDAL binaries from kyngchaos . You will then need to add the installed location /Library/Frameworks/GDAL.framework/Programs to your system path.","title":"macOS"},{"location":"installation/#windows","text":"The instruction below assumes that you have installed Anaconda . Open Anaconda Prompt and enter the following commands to create a conda environment and install required packages 1 2 3 conda create -n py38 python=3.8 conda activate py38 conda install lidar -c conda-forge When installing the lidar package, if you encounter an error saying Microsoft Visual C++ 14.0 is required , please follow the steps below to fix the error and reinstall lidar . More infomration can be found at this link Fix Python 3 on Windows error - Microsoft Visual C++ 14.0 is required . Download Microsoft Build Tools for Visual Studio 2017 Double click to install the downloaded installer - Microsoft Build Tools for Visual Studio 2017 . Open Microsoft Build Tools for Visual Studio 2017 Select Workloads --> Visual C++ build tools and click the install button","title":"Windows"},{"location":"mounts/","text":"mounts module \u00b6 Module for delineating the nested hierarcy of elevated features (i.e., mounts). DelineateMounts ( in_dem , min_size , min_height , interval , out_dir , bool_shp = False ) \u00b6 Delineates the nested hierarchy of elevated features (i.e., mounts). Parameters: Name Type Description Default in_dem str File path to the input DEM. required min_size int The minimum number of pixels to be considered as an object. required min_height float The minimum depth of the feature to be considered as an object. required interval float The slicing interval. required out_dir str The output directory. required bool_shp bool Whether to generate shapefiles. Defaults to False. False Returns: Type Description tuple File paths to the depression ID and level. Source code in lidar/mounts.py def DelineateMounts ( in_dem , min_size , min_height , interval , out_dir , bool_shp = False ): \"\"\"Delineates the nested hierarchy of elevated features (i.e., mounts). Args: in_dem (str): File path to the input DEM. min_size (int): The minimum number of pixels to be considered as an object. min_height (float): The minimum depth of the feature to be considered as an object. interval (float): The slicing interval. out_dir (str): The output directory. bool_shp (bool, optional): Whether to generate shapefiles. Defaults to False. Returns: tuple: File paths to the depression ID and level. \"\"\" if not os . path . exists ( out_dir ): os . mkdir ( out_dir ) print ( \"Loading data ...\" ) dem = rd . LoadGDAL ( in_dem ) # projection = dem.projection geotransform = dem . geotransform cell_size = np . round ( geotransform [ 1 ], decimals = 3 ) out_dem = os . path . join ( out_dir , \"dem_flip.tif\" ) in_dem = FlipDEM ( dem , delta = 100 , out_file = out_dem ) min_elev , max_elev , no_data = get_min_max_nodata ( dem ) print ( \"min = {:.2f} , max = {:.2f} , no_data = {} , cell_size = {} \" . format ( min_elev , max_elev , no_data , cell_size ) ) sink_path = ExtractSinks ( in_dem , min_size , out_dir ) dep_id_path , dep_level_path = DelineateDepressions ( sink_path , min_size , min_height , interval , out_dir , bool_shp ) return dep_id_path , dep_level_path FlipDEM ( dem , delta = 100 , out_file = None ) \u00b6 Flips the DEM. Parameters: Name Type Description Default dem np.array The numpy array containing the image. required delta int The base value to be added to the flipped DEM. Defaults to 100. 100 out_file str File path to the output image. Defaults to None. None Returns: Type Description np.array The numpy array containing the flipped DEM. Source code in lidar/mounts.py def FlipDEM ( dem , delta = 100 , out_file = None ): \"\"\"Flips the DEM. Args: dem (np.array): The numpy array containing the image. delta (int, optional): The base value to be added to the flipped DEM. Defaults to 100. out_file (str, optional): File path to the output image. Defaults to None. Returns: np.array: The numpy array containing the flipped DEM. \"\"\" # get min and max elevation of the dem no_data = dem . no_data max_elev = np . float ( np . max ( dem [ dem != no_data ])) # min_elev = np.float(np.min(dem[dem != no_data])) dem = dem * ( - 1 ) + max_elev + delta dem [ dem == no_data * ( - 1 )] = no_data if out_file is not None : print ( \"Saving flipped dem ...\" ) rd . SaveGDAL ( out_file , dem ) return out_file return dem get_min_max_nodata ( dem ) \u00b6 Gets the minimum, maximum, and no_data value of a numpy array. Parameters: Name Type Description Default dem np.array The numpy array containing the image. required Returns: Type Description tuple The minimum, maximum, and no_data value. Source code in lidar/mounts.py def get_min_max_nodata ( dem ): \"\"\"Gets the minimum, maximum, and no_data value of a numpy array. Args: dem (np.array): The numpy array containing the image. Returns: tuple: The minimum, maximum, and no_data value. \"\"\" no_data = dem . no_data max_elev = np . float ( np . max ( dem [ dem != no_data ])) min_elev = np . float ( np . min ( dem [ dem != no_data ])) return min_elev , max_elev , no_data","title":"mounts module"},{"location":"mounts/#mounts-module","text":"Module for delineating the nested hierarcy of elevated features (i.e., mounts).","title":"mounts module"},{"location":"mounts/#lidar.mounts.DelineateMounts","text":"Delineates the nested hierarchy of elevated features (i.e., mounts). Parameters: Name Type Description Default in_dem str File path to the input DEM. required min_size int The minimum number of pixels to be considered as an object. required min_height float The minimum depth of the feature to be considered as an object. required interval float The slicing interval. required out_dir str The output directory. required bool_shp bool Whether to generate shapefiles. Defaults to False. False Returns: Type Description tuple File paths to the depression ID and level. Source code in lidar/mounts.py def DelineateMounts ( in_dem , min_size , min_height , interval , out_dir , bool_shp = False ): \"\"\"Delineates the nested hierarchy of elevated features (i.e., mounts). Args: in_dem (str): File path to the input DEM. min_size (int): The minimum number of pixels to be considered as an object. min_height (float): The minimum depth of the feature to be considered as an object. interval (float): The slicing interval. out_dir (str): The output directory. bool_shp (bool, optional): Whether to generate shapefiles. Defaults to False. Returns: tuple: File paths to the depression ID and level. \"\"\" if not os . path . exists ( out_dir ): os . mkdir ( out_dir ) print ( \"Loading data ...\" ) dem = rd . LoadGDAL ( in_dem ) # projection = dem.projection geotransform = dem . geotransform cell_size = np . round ( geotransform [ 1 ], decimals = 3 ) out_dem = os . path . join ( out_dir , \"dem_flip.tif\" ) in_dem = FlipDEM ( dem , delta = 100 , out_file = out_dem ) min_elev , max_elev , no_data = get_min_max_nodata ( dem ) print ( \"min = {:.2f} , max = {:.2f} , no_data = {} , cell_size = {} \" . format ( min_elev , max_elev , no_data , cell_size ) ) sink_path = ExtractSinks ( in_dem , min_size , out_dir ) dep_id_path , dep_level_path = DelineateDepressions ( sink_path , min_size , min_height , interval , out_dir , bool_shp ) return dep_id_path , dep_level_path","title":"DelineateMounts()"},{"location":"mounts/#lidar.mounts.FlipDEM","text":"Flips the DEM. Parameters: Name Type Description Default dem np.array The numpy array containing the image. required delta int The base value to be added to the flipped DEM. Defaults to 100. 100 out_file str File path to the output image. Defaults to None. None Returns: Type Description np.array The numpy array containing the flipped DEM. Source code in lidar/mounts.py def FlipDEM ( dem , delta = 100 , out_file = None ): \"\"\"Flips the DEM. Args: dem (np.array): The numpy array containing the image. delta (int, optional): The base value to be added to the flipped DEM. Defaults to 100. out_file (str, optional): File path to the output image. Defaults to None. Returns: np.array: The numpy array containing the flipped DEM. \"\"\" # get min and max elevation of the dem no_data = dem . no_data max_elev = np . float ( np . max ( dem [ dem != no_data ])) # min_elev = np.float(np.min(dem[dem != no_data])) dem = dem * ( - 1 ) + max_elev + delta dem [ dem == no_data * ( - 1 )] = no_data if out_file is not None : print ( \"Saving flipped dem ...\" ) rd . SaveGDAL ( out_file , dem ) return out_file return dem","title":"FlipDEM()"},{"location":"mounts/#lidar.mounts.get_min_max_nodata","text":"Gets the minimum, maximum, and no_data value of a numpy array. Parameters: Name Type Description Default dem np.array The numpy array containing the image. required Returns: Type Description tuple The minimum, maximum, and no_data value. Source code in lidar/mounts.py def get_min_max_nodata ( dem ): \"\"\"Gets the minimum, maximum, and no_data value of a numpy array. Args: dem (np.array): The numpy array containing the image. Returns: tuple: The minimum, maximum, and no_data value. \"\"\" no_data = dem . no_data max_elev = np . float ( np . max ( dem [ dem != no_data ])) min_elev = np . float ( np . min ( dem [ dem != no_data ])) return min_elev , max_elev , no_data","title":"get_min_max_nodata()"},{"location":"slicing/","text":"slicing module \u00b6 Module for the level-set algorithm. Depression \u00b6 The class for storing depression info. DelineateDepressions ( in_sink , min_size , min_depth , interval , out_dir , bool_level_shp = False ) \u00b6 Delineates nested depressions. Parameters: Name Type Description Default in_sink str The file path to the sink image. required min_size int The minimum number of pixels to be considered as a depression. required min_depth float The minimum depth to be considered as a depression. required interval float The slicing interval. required out_dir str The file path to the output directory. required bool_level_shp bool Whether to generate shapefiles for each individual level. Defaults to False. False Returns: Type Description tuple The output level image, and the output object image. Source code in lidar/slicing.py def DelineateDepressions ( in_sink , min_size , min_depth , interval , out_dir , bool_level_shp = False ): \"\"\"Delineates nested depressions. Args: in_sink (str): The file path to the sink image. min_size (int): The minimum number of pixels to be considered as a depression. min_depth (float): The minimum depth to be considered as a depression. interval (float): The slicing interval. out_dir (str): The file path to the output directory. bool_level_shp (bool, optional): Whether to generate shapefiles for each individual level. Defaults to False. Returns: tuple: The output level image, and the output object image. \"\"\" # The following parameters can be used by default interval = interval * ( - 1 ) # convert slicing interval to negative value out_img_dir = os . path . join ( out_dir , \"img-level\" ) out_shp_dir = os . path . join ( out_dir , \"shp-level\" ) out_obj_file = os . path . join ( out_dir , \"depression_id.tif\" ) out_level_file = os . path . join ( out_dir , \"depression_level.tif\" ) out_vec_file = os . path . join ( out_dir , \"depressions.shp\" ) out_csv_file = os . path . join ( out_dir , \"depressions_info.csv\" ) init_time = time . time () # delete contents in output folder if existing if not os . path . exists ( out_dir ): os . mkdir ( out_dir ) if os . path . exists ( out_img_dir ): shutil . rmtree ( out_img_dir ) os . mkdir ( out_img_dir ) if os . path . exists ( out_shp_dir ): shutil . rmtree ( out_shp_dir ) os . mkdir ( out_shp_dir ) print ( \"Reading data ...\" ) read_time = time . time () image = rd . LoadGDAL ( in_sink ) no_data_raw , projection , geotransform , resolution = getMetadata ( image ) rows_cols = image . shape print ( \"rows, cols: \" + str ( rows_cols )) print ( \"Pixel resolution: \" + str ( resolution )) print ( \"Read data time: {:.4f} seconds\" . format ( time . time () - read_time )) min_elev , max_elev , no_data = get_min_max_nodata ( image ) # set nodata value to a large value, e.g., 9999 # initialize output image obj_image = np . zeros ( image . shape ) # output depression image with unique id for each nested depression level_image = np . zeros ( image . shape ) # output depression level image # nb_labels is the total number of objects. 0 represents background object. label_objects , nb_labels = regionGroup ( image , min_size , no_data ) # regions = measure.regionprops(label_objects, image, coordinates='xy') regions = measure . regionprops ( label_objects , image ) del image # delete the original image to save memory prep_time = time . time () print ( \"Data preparation time: {:.4f} seconds\" . format ( prep_time - init_time )) print ( \"Total number of regions: {} \" . format ( nb_labels )) identify_time = time . time () obj_uid = 0 global_dep_list = [] # loop through regions and identify nested depressions in each region using level-set method for region in regions : # iterate through each depression region region_id = region . label img = region . intensity_image # dem subset for each region bbox = region . bbox # save all input parameters needed for level set methods as a dict image_paras = set_image_paras ( no_data , min_size , min_depth , interval , resolution ) # execute level set methods out_obj , dep_list = levelSet ( img , region_id , obj_uid , image_paras ) for dep in dep_list : global_dep_list . append ( dep ) obj_uid += len ( dep_list ) level_obj = obj_to_level ( out_obj , global_dep_list ) obj_image = writeObject ( obj_image , out_obj , bbox ) # write region to whole image level_image = writeObject ( level_image , level_obj , bbox ) del out_obj , level_obj , region del regions , label_objects print ( \"=========== Run time statistics =========== \" ) print ( \"(rows, cols): \\t\\t\\t {0} \" . format ( str ( rows_cols ))) print ( \"Pixel resolution: \\t\\t {0} m\" . format ( str ( resolution ))) print ( \"Number of regions: \\t\\t {0} \" . format ( str ( nb_labels ))) print ( \"Data preparation time: \\t\\t {:.4f} s\" . format ( prep_time - init_time )) print ( \"Identify level time: \\t\\t {:.4f} s\" . format ( time . time () - identify_time )) write_time = time . time () # writeRaster(obj_image, out_obj_file, in_sink) # writeRaster(level_image, out_level_file, in_sink) # SaveGDAL function can only save data as floating point level_image = np2rdarray ( np . int32 ( level_image ), no_data_raw , projection , geotransform ) rd . SaveGDAL ( out_level_file , level_image ) obj_image = np2rdarray ( np . int32 ( obj_image ), no_data_raw , projection , geotransform ) rd . SaveGDAL ( out_obj_file , obj_image ) print ( \"Write image time: \\t\\t {:.4f} s\" . format ( time . time () - write_time )) # converting object image to polygon level_time = time . time () polygonize ( out_obj_file , out_vec_file ) write_dep_csv ( global_dep_list , out_csv_file ) print ( \"Polygonize time: \\t\\t {:.4f} s\" . format ( time . time () - level_time )) # extracting polygons for each individual level if bool_level_shp : level_time = time . time () extract_levels ( level_image , obj_image , min_size , no_data , out_img_dir , out_shp_dir , in_sink , False ) print ( \"Extract level time: \\t\\t {:.4f} s\" . format ( time . time () - level_time )) shutil . rmtree ( out_img_dir ) else : shutil . rmtree ( out_shp_dir ) shutil . rmtree ( out_img_dir ) del level_image del obj_image end_time = time . time () print ( \"Total run time: \\t\\t\\t {:.4f} s\" . format ( end_time - init_time )) return out_obj_file , out_level_file extract_levels ( level_img , obj_img , min_size , no_data , out_img_dir , out_shp_dir , template , bool_comb = False ) \u00b6 Extracts individual level image. Parameters: Name Type Description Default level_img np.array The numpy array containing the level image. required obj_img np.array The numpy array containing the object image. required min_size int The minimum number of pixels to be considered as a depression. required no_data float The no_data value of the image. required out_img_dir str The output image directory. required out_shp_dir str The output shapefile directory. required template str The file path to the template image. required bool_comb bool Whether to extract combined level image. Defaults to False. False Returns: Type Description tuple The single level image, properties of region grouped level image, properties of region grouped object image. Source code in lidar/slicing.py def extract_levels ( level_img , obj_img , min_size , no_data , out_img_dir , out_shp_dir , template , bool_comb = False ): \"\"\"Extracts individual level image. Args: level_img (np.array): The numpy array containing the level image. obj_img (np.array): The numpy array containing the object image. min_size (int): The minimum number of pixels to be considered as a depression. no_data (float): The no_data value of the image. out_img_dir (str): The output image directory. out_shp_dir (str): The output shapefile directory. template (str): The file path to the template image. bool_comb (bool, optional): Whether to extract combined level image. Defaults to False. Returns: tuple: The single level image, properties of region grouped level image, properties of region grouped object image. \"\"\" max_level = int ( np . max ( level_img )) combined_images = [] single_images = [] img = np . copy ( level_img ) digits = int ( math . log10 ( max_level )) + 1 # determine the level number of output file name for i in range ( 1 , max_level + 1 ): img [( img > 0 ) & ( img <= i ) ] = i tmp_img = np . copy ( img ) tmp_img [ tmp_img > i ] = 0 if bool_comb == True : # whether to extract combined level image combined_images . append ( np . copy ( tmp_img )) filename_combined = \"Combined_level_\" + str ( i ) . zfill ( digits ) + \".tif\" out_file = os . path . join ( out_shp_dir , filename_combined ) writeRaster ( tmp_img , out_file , template ) lbl_objects , n_labels = regionGroup ( tmp_img , min_size , no_data ) # regs = measure.regionprops(lbl_objects, level_img, coordinates='xy') regs = measure . regionprops ( lbl_objects , level_img ) # regs2 = measure.regionprops(lbl_objects, obj_img, coordinates='xy') regs2 = measure . regionprops ( lbl_objects , obj_img ) sin_img = np . zeros ( img . shape ) for index , reg in enumerate ( regs ): uid = regs2 [ index ] . min_intensity if reg . max_intensity >= i : bbox = reg . bbox tmp_img = np . zeros ( reg . image . shape ) tmp_img [ reg . image ] = uid writeObject ( sin_img , tmp_img , bbox ) # for reg in regs: # if reg.max_intensity >= i: # bbox = reg.bbox # tmp_img = np.zeros(reg.image.shape) # tmp_img[reg.image] = i # writeObject(sin_img, tmp_img, bbox) del tmp_img # single_images.append(np.copy(sin_img)) filename_single = \"Single_level_\" + str ( i ) . zfill ( digits ) + \".shp\" out_shp_file = os . path . join ( out_shp_dir , filename_single ) out_img_file = os . path . join ( out_img_dir , \"tmp.tif\" ) writeRaster ( sin_img , out_img_file , template ) polygonize ( out_img_file , out_shp_file ) # writeRaster(sin_img,out_file,template) del sin_img , regs , regs2 del img return True get_image_paras ( image_paras ) \u00b6 Gets image parameters. Parameters: Name Type Description Default image_paras dict The dictionary containing image parameters. required Returns: Type Description tuple A tuple containing no_data, min_size, min_depth, interval, resolution. Source code in lidar/slicing.py def get_image_paras ( image_paras ): \"\"\"Gets image parameters. Args: image_paras (dict): The dictionary containing image parameters. Returns: tuple: A tuple containing no_data, min_size, min_depth, interval, resolution. \"\"\" no_data = image_paras [ \"no_data\" ] min_size = image_paras [ \"min_size\" ] min_depth = image_paras [ \"min_depth\" ] interval = image_paras [ \"interval\" ] resolution = image_paras [ \"resolution\" ] return no_data , min_size , min_depth , interval , resolution get_min_max_nodata ( image ) \u00b6 Gets the minimum, maximum, and no_data value of a numpy array. Parameters: Name Type Description Default image np.array The numpy array containing the image. required Returns: Type Description tuple The minimum, maximum, and no_data value. Source code in lidar/slicing.py def get_min_max_nodata ( image ): \"\"\"Gets the minimum, maximum, and no_data value of a numpy array. Args: image (np.array): The numpy array containing the image. Returns: tuple: The minimum, maximum, and no_data value. \"\"\" max_elev = np . max ( image ) nodata = pow ( 10 , math . floor ( math . log10 ( np . max ( image ))) + 2 ) - 1 # assign no data value image [ image <= 0 ] = nodata # change no data value min_elev = np . min ( image ) return min_elev , max_elev , nodata getMetadata ( img ) \u00b6 Gets rdarray metadata. Parameters: Name Type Description Default img rdarray The richDEM array containing the image. required Returns: Type Description tuple no_data, projection, geotransform, cell_size Source code in lidar/slicing.py def getMetadata ( img ): \"\"\"Gets rdarray metadata. Args: img (rdarray): The richDEM array containing the image. Returns: tuple: no_data, projection, geotransform, cell_size \"\"\" no_data = img . no_data projection = img . projection geotransform = img . geotransform cell_size = np . round ( geotransform [ 1 ], decimals = 2 ) return no_data , projection , geotransform , cell_size img_to_shp ( in_img_dir , out_shp_dir ) \u00b6 Converts images in a selected folder to shapefiles Parameters: Name Type Description Default in_img_dir str The input iimage directory. required out_shp_dir str The output shapefile directory. required Source code in lidar/slicing.py def img_to_shp ( in_img_dir , out_shp_dir ): \"\"\"Converts images in a selected folder to shapefiles Args: in_img_dir (str): The input iimage directory. out_shp_dir (str): The output shapefile directory. \"\"\" img_files = os . listdir ( in_img_dir ) for img_file in img_files : if img_file . endswith ( \".tif\" ): img_filename = os . path . join ( in_img_dir , img_file ) shp_filename = os . path . join ( out_shp_dir , img_file . replace ( \"tif\" , \"shp\" )) polygonize ( img_filename , shp_filename ) levelSet ( img , region_id , obj_uid , image_paras ) \u00b6 Identifies nested depressions using level-set method. Parameters: Name Type Description Default img np.array The numpy array containing the image. required region_id int The unique id of the region. required obj_uid int The object id of the region. required image_paras dict The dictionary containing image parameters. required Returns: Type Description tuple (level image, depression list) Source code in lidar/slicing.py def levelSet ( img , region_id , obj_uid , image_paras ): \"\"\"Identifies nested depressions using level-set method. Args: img (np.array): The numpy array containing the image. region_id (int): The unique id of the region. obj_uid (int): The object id of the region. image_paras (dict): The dictionary containing image parameters. Returns: tuple: (level image, depression list) \"\"\" # unzip input parameters from dict no_data , min_size , min_depth , interval , resolution = get_image_paras ( image_paras ) level_img = np . zeros ( img . shape ) # init output level image # flood_img = np.zeros(img.shape) # init output flood time image max_elev = np . max ( img ) img [ img == 0 ] = no_data min_elev = np . min ( img ) print ( \"Processing Region # {} ...\" . format ( region_id )) # print(\"=========================================================================== Region: {}\".format(region_id)) unique_id = obj_uid parent_ids = {} # store current parent depressions nbr_ids = {} # store the inner-neighbor ids of current parent depressions dep_list = [] # list for storing depressions ( rows , cols ) = img . shape if rows == 1 or cols == 1 : # if the depression is a horizontal or vertical line cells = rows * cols size = cells * pow ( resolution , 2 ) # depression size max_depth = max_elev - min_elev mean_depth = ( max_elev * cells - np . sum ( img )) / cells volume = mean_depth * cells * pow ( resolution , 2 ) unique_id += 1 level = 1 perimeter = cells * resolution major_axis = cells * resolution minor_axis = resolution area_bbox_ratio = 1 if rows == 1 : elongatedness = cols eccentricity = 1 orientation = 0 else : elongatedness = rows eccentricity = 1 orientation = 90 dep_list . append ( Depression ( unique_id , level , cells , size , volume , mean_depth , max_depth , min_elev , max_elev , [], region_id , perimeter , major_axis , minor_axis , elongatedness , eccentricity , orientation , area_bbox_ratio )) level_img = np . ones ( img . shape ) del img return level_img , dep_list for elev in np . arange ( max_elev , min_elev , interval ): # slicing operation using top-down approach img [ img > elev ] = 0 # set elevation higher than xy-plane to zero label_objects , nb_labels = regionGroup ( img , min_size , no_data ) # print('slicing elev = {:.2f}, number of objects = {}'.format(elev, nb_labels)) if nb_labels == 0 : # if slicing results in no objects, quit break # objects = measure.regionprops(label_objects, img, coordinates='xy') objects = measure . regionprops ( label_objects , img ) for i , object in enumerate ( objects ): ( row , col ) = object . coords [ 0 ] # get a boundary cell bbox = object . bbox if len ( parent_ids ) == 0 : # This is the first depression, maximum depression # print(\"This is the maximum depression extent.\") cells = object . area size = cells * pow ( resolution , 2 ) # depression size max_depth = object . max_intensity - object . min_intensity # depression max depth mean_depth = ( object . max_intensity * cells - np . sum ( object . intensity_image )) / cells # depression mean depth volume = mean_depth * cells * pow ( resolution , 2 ) # depression volume # spill_elev = object.max_intensity # to be implemented min_elev = object . min_intensity # depression min elevation max_elev = object . max_intensity # depression max elevation # print(\"size = {}, max depth = {:.2f}, mean depth = {:.2f}, volume = {:.2f}, spill elev = {:.2f}\".format( # size, max_depth, mean_depth, volume, spill_elev)) unique_id += 1 level = 1 perimeter = object . perimeter * resolution major_axis = object . major_axis_length * resolution minor_axis = object . minor_axis_length * resolution if minor_axis == 0 : minor_axis = resolution elongatedness = major_axis * 1.0 / minor_axis eccentricity = object . eccentricity orientation = object . orientation / 3.1415 * 180 area_bbox_ratio = object . extent dep_list . append ( Depression ( unique_id , level , cells , size , volume , mean_depth , max_depth , min_elev , max_elev ,[], region_id , perimeter , major_axis , minor_axis , elongatedness , eccentricity , orientation , area_bbox_ratio )) parent_ids [ unique_id ] = 0 # number of inner neighbors nbr_ids [ unique_id ] = [] # ids of inner neighbors tmp_img = np . zeros ( object . image . shape ) tmp_img [ object . image ] = unique_id writeObject ( level_img , tmp_img , bbox ) # write the object to the final image else : # identify inner neighbors of parent depressions # print(\"current id: {}\".format(parent_ids.keys())) # (row, col) = object.coords[0] parent_id = level_img [ row , col ] parent_ids [ parent_id ] += 1 nbr_ids [ parent_id ] . append ( i ) for key in parent_ids . copy (): # check how many inner neighbors each upper level depression has if parent_ids [ key ] > 1 : # if the parent has two or more children # print(\"Object id: {} has split into {} objects\".format(key, parent_ids[key])) new_parent_keys = nbr_ids [ key ] for new_key in new_parent_keys : object = objects [ new_key ] cells = object . area size = cells * pow ( resolution , 2 ) max_depth = object . max_intensity - object . min_intensity mean_depth = ( object . max_intensity * cells - np . sum ( object . intensity_image )) / cells volume = mean_depth * cells * pow ( resolution , 2 ) spill_elev = object . max_intensity min_elev = object . min_intensity max_elev = object . max_intensity # print(\" -- size = {}, max depth = {:.2f}, mean depth = {:.2f}, volume = {:.2f}, spill elev = {:.2f}\".format( # size, max_depth, mean_depth, volume, spill_elev)) unique_id += 1 level = 1 perimeter = object . perimeter * resolution major_axis = object . major_axis_length * resolution minor_axis = object . minor_axis_length * resolution if minor_axis == 0 : minor_axis = resolution elongatedness = major_axis * 1.0 / minor_axis eccentricity = object . eccentricity orientation = object . orientation / 3.1415 * 180 area_bbox_ratio = object . extent dep_list . append ( Depression ( unique_id , level , cells , size , volume , mean_depth , max_depth , min_elev , max_elev , [], region_id , perimeter , major_axis , minor_axis , elongatedness , eccentricity , orientation , area_bbox_ratio )) dep_list [ key - 1 - obj_uid ] . inNbrId . append ( unique_id ) parent_ids [ unique_id ] = 0 nbr_ids [ unique_id ] = [] bbox = object . bbox tmp_img = np . zeros ( object . image . shape ) tmp_img [ object . image ] = unique_id writeObject ( level_img , tmp_img , bbox ) if key in parent_ids . keys (): # remove parent id that has split parent_ids . pop ( key ) else : parent_ids [ key ] = 0 # if a parent depression has not split, keep it nbr_ids [ key ] = [] # for dep in dep_list: # print(\"id: {} has children {}\".format(dep.id, dep.inNbrId)) dep_list = updateLevel ( dep_list , obj_uid ) # update the inner neighbors of each depression # for dep in dep_list: # print(\"id: {} is level {}\".format(dep.id, dep.level)) del img return level_img , dep_list np2rdarray ( in_array , no_data , projection , geotransform ) \u00b6 Converts numpy array to rdarray. Parameters: Name Type Description Default in_array np.array The input numpy array containing the image. required no_data float The no_data value of the image. required projection str The projection coordinate system of the image. required geotransform str The geotransform of the image. required Returns: Type Description rdarray The richDEM array containing the image. Source code in lidar/slicing.py def np2rdarray ( in_array , no_data , projection , geotransform ): \"\"\"Converts numpy array to rdarray. Args: in_array (np.array): The input numpy array containing the image. no_data (float): The no_data value of the image. projection (str): The projection coordinate system of the image. geotransform (str): The geotransform of the image. Returns: rdarray: The richDEM array containing the image. \"\"\" out_array = rd . rdarray ( in_array , no_data = no_data ) out_array . projection = projection out_array . geotransform = geotransform return out_array obj_to_level ( obj_img , dep_list ) \u00b6 Derives depression level image based on the depression id image and depression list. Parameters: Name Type Description Default obj_img np.array The numpy array containing the object image. required dep_list list A list containing depression info. required Returns: Type Description np.array The numpy array containing the object level image. Source code in lidar/slicing.py def obj_to_level ( obj_img , dep_list ): \"\"\"Derives depression level image based on the depression id image and depression list. Args: obj_img (np.array): The numpy array containing the object image. dep_list (list): A list containing depression info. Returns: np.array: The numpy array containing the object level image. \"\"\" level_img = np . copy ( obj_img ) max_id = int ( np . max ( level_img )) # print(\"max id = \" + str(max_id)) if max_id > 0 : min_id = int ( np . min ( level_img [ np . nonzero ( level_img )])) # print(\"min_id = \" + str(min_id)) for i in range ( min_id , max_id + 1 ): level_img [ level_img == i ] = dep_list [ i - 1 ] . level + max_id level_img = level_img - max_id return level_img polygonize ( img , shp_path ) \u00b6 Converts a raster image to vector. Parameters: Name Type Description Default img str File path to the input image. required shp_path str File path to the output shapefile. required Source code in lidar/slicing.py def polygonize ( img , shp_path ): \"\"\"Converts a raster image to vector. Args: img (str): File path to the input image. shp_path (str): File path to the output shapefile. \"\"\" # mapping between gdal type and ogr field type type_mapping = { gdal . GDT_Byte : ogr . OFTInteger , gdal . GDT_UInt16 : ogr . OFTInteger , gdal . GDT_Int16 : ogr . OFTInteger , gdal . GDT_UInt32 : ogr . OFTInteger , gdal . GDT_Int32 : ogr . OFTInteger , gdal . GDT_Float32 : ogr . OFTReal , gdal . GDT_Float64 : ogr . OFTReal , gdal . GDT_CInt16 : ogr . OFTInteger , gdal . GDT_CInt32 : ogr . OFTInteger , gdal . GDT_CFloat32 : ogr . OFTReal , gdal . GDT_CFloat64 : ogr . OFTReal } ds = gdal . Open ( img ) prj = ds . GetProjection () srcband = ds . GetRasterBand ( 1 ) dst_layername = \"Shape\" drv = ogr . GetDriverByName ( \"ESRI Shapefile\" ) dst_ds = drv . CreateDataSource ( shp_path ) srs = osr . SpatialReference ( wkt = prj ) dst_layer = dst_ds . CreateLayer ( dst_layername , srs = srs ) raster_field = ogr . FieldDefn ( 'id' , type_mapping [ srcband . DataType ]) dst_layer . CreateField ( raster_field ) gdal . Polygonize ( srcband , srcband , dst_layer , 0 , [], callback = None ) del img , ds , srcband , dst_ds , dst_layer regionGroup ( img_array , min_size , no_data ) \u00b6 IdentifIies regions based on region growing method Parameters: Name Type Description Default img_array np.array The numpy array containing the image. required min_size int The minimum number of pixels to be considered as a depression. required no_data float The no_data value of the image. required Returns: Type Description tuple The labelled objects and total number of labels. Source code in lidar/slicing.py def regionGroup ( img_array , min_size , no_data ): \"\"\"IdentifIies regions based on region growing method Args: img_array (np.array): The numpy array containing the image. min_size (int): The minimum number of pixels to be considered as a depression. no_data (float): The no_data value of the image. Returns: tuple: The labelled objects and total number of labels. \"\"\" img_array [ img_array == no_data ] = 0 label_objects , nb_labels = ndimage . label ( img_array ) sizes = np . bincount ( label_objects . ravel ()) mask_sizes = sizes > min_size mask_sizes [ 0 ] = 0 image_cleaned = mask_sizes [ label_objects ] label_objects , nb_labels = ndimage . label ( image_cleaned ) # nb_labels is the total number of objects. 0 represents background object. return label_objects , nb_labels set_image_paras ( no_data , min_size , min_depth , interval , resolution ) \u00b6 Sets the input image parameters for level-set method. Parameters: Name Type Description Default no_data float The no_data value of the input DEM. required min_size int The minimum nuber of pixels to be considered as a depressioin. required min_depth float The minimum depth to be considered as a depression. required interval float The slicing interval. required resolution float The spatial resolution of the DEM. required Returns: Type Description dict A dictionary containing image parameters. Source code in lidar/slicing.py def set_image_paras ( no_data , min_size , min_depth , interval , resolution ): \"\"\"Sets the input image parameters for level-set method. Args: no_data (float): The no_data value of the input DEM. min_size (int): The minimum nuber of pixels to be considered as a depressioin. min_depth (float): The minimum depth to be considered as a depression. interval (float): The slicing interval. resolution (float): The spatial resolution of the DEM. Returns: dict: A dictionary containing image parameters. \"\"\" image_paras = {} image_paras [ \"no_data\" ] = no_data image_paras [ \"min_size\" ] = min_size image_paras [ \"min_depth\" ] = min_depth image_paras [ \"interval\" ] = interval image_paras [ \"resolution\" ] = resolution return image_paras updateLevel ( dep_list , obj_uid ) \u00b6 Updates the inner neighbors of each depression. Parameters: Name Type Description Default dep_list list A list containing depression info. required obj_uid int The unique id of an object. required Returns: Type Description list A list containing depression info. Source code in lidar/slicing.py def updateLevel ( dep_list , obj_uid ): \"\"\"Updates the inner neighbors of each depression. Args: dep_list (list): A list containing depression info. obj_uid (int): The unique id of an object. Returns: list: A list containing depression info. \"\"\" for dep in reversed ( dep_list ): if len ( dep . inNbrId ) == 0 : dep . level = 1 else : max_children_level = 0 for id in dep . inNbrId : if dep_list [ id - 1 - obj_uid ] . level > max_children_level : max_children_level = dep_list [ id - 1 - obj_uid ] . level dep . level = max_children_level + 1 return dep_list write_dep_csv ( dep_list , csv_file ) \u00b6 Saves the depression list to a CSV file. Parameters: Name Type Description Default dep_list list A list containing depression info. required csv_file str File path to the output CSV file. required Source code in lidar/slicing.py def write_dep_csv ( dep_list , csv_file ): \"\"\"Saves the depression list to a CSV file. Args: dep_list (list): A list containing depression info. csv_file (str): File path to the output CSV file. \"\"\" csv = open ( csv_file , \"w\" ) header = \"id\" + \",\" + \"level\" + \",\" + \"count\" + \",\" + \"area\" + \",\" + \"volume\" + \",\" + \"avg-depth\" + \",\" + \"max-depth\" + \",\" + \\ \"min-elev\" + \",\" + \"max-elev\" + \",\" + \"children-id\" + \",\" + \"region-id\" + \",\" + \"perimeter\" + \",\" + \"major-axis\" + \\ \",\" + \"minor-axis\" + \",\" + \"elongatedness\" + \",\" + \"eccentricity\" + \",\" + \"orientation\" + \",\" + \\ \"area-bbox-ratio\" csv . write ( header + \" \\n \" ) for dep in dep_list : # id, level, size, volume, meanDepth, maxDepth, minElev, bndElev, inNbrId, nbrId = 0 line = \" {} , {} , {} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {} , {} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} ,\" \\ \" {:.2f} \" . format ( dep . id , dep . level , dep . count , dep . size , dep . volume , dep . meanDepth , dep . maxDepth , dep . minElev , dep . bndElev , str ( dep . inNbrId ) . replace ( \",\" , \":\" ), dep . regionId , dep . perimeter , dep . major_axis , dep . minor_axis , dep . elongatedness , dep . eccentricity , dep . orientation , dep . area_bbox_ratio ) csv . write ( line + \" \\n \" ) csv . close () writeObject ( img_array , obj_array , bbox ) \u00b6 Writes depression objects to the original image. Parameters: Name Type Description Default img_array np.array The output image array. required obj_array np.array The numpy array containing depression objects. required bbox list The bounding box of the depression object. required Returns: Type Description np.array The numpy array containing the depression objects. Source code in lidar/slicing.py def writeObject ( img_array , obj_array , bbox ): \"\"\"Writes depression objects to the original image. Args: img_array (np.array): The output image array. obj_array (np.array): The numpy array containing depression objects. bbox (list): The bounding box of the depression object. Returns: np.array: The numpy array containing the depression objects. \"\"\" min_row , min_col , max_row , max_col = bbox roi = img_array [ min_row : max_row , min_col : max_col ] roi [ obj_array > 0 ] = obj_array [ obj_array > 0 ] return img_array writeRaster ( arr , out_path , template ) \u00b6 Saves an numpy array as a GeoTIFF. Parameters: Name Type Description Default arr np.array The numpy array containing the image. required out_path str The file path to the output GeoTIFF. required template str The file path to the template image containing projection info. required Returns: Type Description np.array The numpy array containing the image. Source code in lidar/slicing.py def writeRaster ( arr , out_path , template ): \"\"\"Saves an numpy array as a GeoTIFF. Args: arr (np.array): The numpy array containing the image. out_path (str): The file path to the output GeoTIFF. template (str): The file path to the template image containing projection info. Returns: np.array: The numpy array containing the image. \"\"\" no_data = 0 # First of all, gather some information from the template file data = gdal . Open ( template ) [ cols , rows ] = arr . shape trans = data . GetGeoTransform () proj = data . GetProjection () # nodatav = 0 #data.GetNoDataValue() # Create the file, using the information from the template file outdriver = gdal . GetDriverByName ( \"GTiff\" ) # http://www.gdal.org/gdal_8h.html # GDT_Byte = 1, GDT_UInt16 = 2, GDT_UInt32 = 4, GDT_Int32 = 5, GDT_Float32 = 6, outdata = outdriver . Create ( str ( out_path ), rows , cols , 1 , gdal . GDT_UInt32 ) # Write the array to the file, which is the original array in this example outdata . GetRasterBand ( 1 ) . WriteArray ( arr ) # Set a no data value if required outdata . GetRasterBand ( 1 ) . SetNoDataValue ( no_data ) # Georeference the image outdata . SetGeoTransform ( trans ) # Write projection information outdata . SetProjection ( proj ) return arr","title":"slicing module"},{"location":"slicing/#slicing-module","text":"Module for the level-set algorithm.","title":"slicing module"},{"location":"slicing/#lidar.slicing.Depression","text":"The class for storing depression info.","title":"Depression"},{"location":"slicing/#lidar.slicing.DelineateDepressions","text":"Delineates nested depressions. Parameters: Name Type Description Default in_sink str The file path to the sink image. required min_size int The minimum number of pixels to be considered as a depression. required min_depth float The minimum depth to be considered as a depression. required interval float The slicing interval. required out_dir str The file path to the output directory. required bool_level_shp bool Whether to generate shapefiles for each individual level. Defaults to False. False Returns: Type Description tuple The output level image, and the output object image. Source code in lidar/slicing.py def DelineateDepressions ( in_sink , min_size , min_depth , interval , out_dir , bool_level_shp = False ): \"\"\"Delineates nested depressions. Args: in_sink (str): The file path to the sink image. min_size (int): The minimum number of pixels to be considered as a depression. min_depth (float): The minimum depth to be considered as a depression. interval (float): The slicing interval. out_dir (str): The file path to the output directory. bool_level_shp (bool, optional): Whether to generate shapefiles for each individual level. Defaults to False. Returns: tuple: The output level image, and the output object image. \"\"\" # The following parameters can be used by default interval = interval * ( - 1 ) # convert slicing interval to negative value out_img_dir = os . path . join ( out_dir , \"img-level\" ) out_shp_dir = os . path . join ( out_dir , \"shp-level\" ) out_obj_file = os . path . join ( out_dir , \"depression_id.tif\" ) out_level_file = os . path . join ( out_dir , \"depression_level.tif\" ) out_vec_file = os . path . join ( out_dir , \"depressions.shp\" ) out_csv_file = os . path . join ( out_dir , \"depressions_info.csv\" ) init_time = time . time () # delete contents in output folder if existing if not os . path . exists ( out_dir ): os . mkdir ( out_dir ) if os . path . exists ( out_img_dir ): shutil . rmtree ( out_img_dir ) os . mkdir ( out_img_dir ) if os . path . exists ( out_shp_dir ): shutil . rmtree ( out_shp_dir ) os . mkdir ( out_shp_dir ) print ( \"Reading data ...\" ) read_time = time . time () image = rd . LoadGDAL ( in_sink ) no_data_raw , projection , geotransform , resolution = getMetadata ( image ) rows_cols = image . shape print ( \"rows, cols: \" + str ( rows_cols )) print ( \"Pixel resolution: \" + str ( resolution )) print ( \"Read data time: {:.4f} seconds\" . format ( time . time () - read_time )) min_elev , max_elev , no_data = get_min_max_nodata ( image ) # set nodata value to a large value, e.g., 9999 # initialize output image obj_image = np . zeros ( image . shape ) # output depression image with unique id for each nested depression level_image = np . zeros ( image . shape ) # output depression level image # nb_labels is the total number of objects. 0 represents background object. label_objects , nb_labels = regionGroup ( image , min_size , no_data ) # regions = measure.regionprops(label_objects, image, coordinates='xy') regions = measure . regionprops ( label_objects , image ) del image # delete the original image to save memory prep_time = time . time () print ( \"Data preparation time: {:.4f} seconds\" . format ( prep_time - init_time )) print ( \"Total number of regions: {} \" . format ( nb_labels )) identify_time = time . time () obj_uid = 0 global_dep_list = [] # loop through regions and identify nested depressions in each region using level-set method for region in regions : # iterate through each depression region region_id = region . label img = region . intensity_image # dem subset for each region bbox = region . bbox # save all input parameters needed for level set methods as a dict image_paras = set_image_paras ( no_data , min_size , min_depth , interval , resolution ) # execute level set methods out_obj , dep_list = levelSet ( img , region_id , obj_uid , image_paras ) for dep in dep_list : global_dep_list . append ( dep ) obj_uid += len ( dep_list ) level_obj = obj_to_level ( out_obj , global_dep_list ) obj_image = writeObject ( obj_image , out_obj , bbox ) # write region to whole image level_image = writeObject ( level_image , level_obj , bbox ) del out_obj , level_obj , region del regions , label_objects print ( \"=========== Run time statistics =========== \" ) print ( \"(rows, cols): \\t\\t\\t {0} \" . format ( str ( rows_cols ))) print ( \"Pixel resolution: \\t\\t {0} m\" . format ( str ( resolution ))) print ( \"Number of regions: \\t\\t {0} \" . format ( str ( nb_labels ))) print ( \"Data preparation time: \\t\\t {:.4f} s\" . format ( prep_time - init_time )) print ( \"Identify level time: \\t\\t {:.4f} s\" . format ( time . time () - identify_time )) write_time = time . time () # writeRaster(obj_image, out_obj_file, in_sink) # writeRaster(level_image, out_level_file, in_sink) # SaveGDAL function can only save data as floating point level_image = np2rdarray ( np . int32 ( level_image ), no_data_raw , projection , geotransform ) rd . SaveGDAL ( out_level_file , level_image ) obj_image = np2rdarray ( np . int32 ( obj_image ), no_data_raw , projection , geotransform ) rd . SaveGDAL ( out_obj_file , obj_image ) print ( \"Write image time: \\t\\t {:.4f} s\" . format ( time . time () - write_time )) # converting object image to polygon level_time = time . time () polygonize ( out_obj_file , out_vec_file ) write_dep_csv ( global_dep_list , out_csv_file ) print ( \"Polygonize time: \\t\\t {:.4f} s\" . format ( time . time () - level_time )) # extracting polygons for each individual level if bool_level_shp : level_time = time . time () extract_levels ( level_image , obj_image , min_size , no_data , out_img_dir , out_shp_dir , in_sink , False ) print ( \"Extract level time: \\t\\t {:.4f} s\" . format ( time . time () - level_time )) shutil . rmtree ( out_img_dir ) else : shutil . rmtree ( out_shp_dir ) shutil . rmtree ( out_img_dir ) del level_image del obj_image end_time = time . time () print ( \"Total run time: \\t\\t\\t {:.4f} s\" . format ( end_time - init_time )) return out_obj_file , out_level_file","title":"DelineateDepressions()"},{"location":"slicing/#lidar.slicing.extract_levels","text":"Extracts individual level image. Parameters: Name Type Description Default level_img np.array The numpy array containing the level image. required obj_img np.array The numpy array containing the object image. required min_size int The minimum number of pixels to be considered as a depression. required no_data float The no_data value of the image. required out_img_dir str The output image directory. required out_shp_dir str The output shapefile directory. required template str The file path to the template image. required bool_comb bool Whether to extract combined level image. Defaults to False. False Returns: Type Description tuple The single level image, properties of region grouped level image, properties of region grouped object image. Source code in lidar/slicing.py def extract_levels ( level_img , obj_img , min_size , no_data , out_img_dir , out_shp_dir , template , bool_comb = False ): \"\"\"Extracts individual level image. Args: level_img (np.array): The numpy array containing the level image. obj_img (np.array): The numpy array containing the object image. min_size (int): The minimum number of pixels to be considered as a depression. no_data (float): The no_data value of the image. out_img_dir (str): The output image directory. out_shp_dir (str): The output shapefile directory. template (str): The file path to the template image. bool_comb (bool, optional): Whether to extract combined level image. Defaults to False. Returns: tuple: The single level image, properties of region grouped level image, properties of region grouped object image. \"\"\" max_level = int ( np . max ( level_img )) combined_images = [] single_images = [] img = np . copy ( level_img ) digits = int ( math . log10 ( max_level )) + 1 # determine the level number of output file name for i in range ( 1 , max_level + 1 ): img [( img > 0 ) & ( img <= i ) ] = i tmp_img = np . copy ( img ) tmp_img [ tmp_img > i ] = 0 if bool_comb == True : # whether to extract combined level image combined_images . append ( np . copy ( tmp_img )) filename_combined = \"Combined_level_\" + str ( i ) . zfill ( digits ) + \".tif\" out_file = os . path . join ( out_shp_dir , filename_combined ) writeRaster ( tmp_img , out_file , template ) lbl_objects , n_labels = regionGroup ( tmp_img , min_size , no_data ) # regs = measure.regionprops(lbl_objects, level_img, coordinates='xy') regs = measure . regionprops ( lbl_objects , level_img ) # regs2 = measure.regionprops(lbl_objects, obj_img, coordinates='xy') regs2 = measure . regionprops ( lbl_objects , obj_img ) sin_img = np . zeros ( img . shape ) for index , reg in enumerate ( regs ): uid = regs2 [ index ] . min_intensity if reg . max_intensity >= i : bbox = reg . bbox tmp_img = np . zeros ( reg . image . shape ) tmp_img [ reg . image ] = uid writeObject ( sin_img , tmp_img , bbox ) # for reg in regs: # if reg.max_intensity >= i: # bbox = reg.bbox # tmp_img = np.zeros(reg.image.shape) # tmp_img[reg.image] = i # writeObject(sin_img, tmp_img, bbox) del tmp_img # single_images.append(np.copy(sin_img)) filename_single = \"Single_level_\" + str ( i ) . zfill ( digits ) + \".shp\" out_shp_file = os . path . join ( out_shp_dir , filename_single ) out_img_file = os . path . join ( out_img_dir , \"tmp.tif\" ) writeRaster ( sin_img , out_img_file , template ) polygonize ( out_img_file , out_shp_file ) # writeRaster(sin_img,out_file,template) del sin_img , regs , regs2 del img return True","title":"extract_levels()"},{"location":"slicing/#lidar.slicing.get_image_paras","text":"Gets image parameters. Parameters: Name Type Description Default image_paras dict The dictionary containing image parameters. required Returns: Type Description tuple A tuple containing no_data, min_size, min_depth, interval, resolution. Source code in lidar/slicing.py def get_image_paras ( image_paras ): \"\"\"Gets image parameters. Args: image_paras (dict): The dictionary containing image parameters. Returns: tuple: A tuple containing no_data, min_size, min_depth, interval, resolution. \"\"\" no_data = image_paras [ \"no_data\" ] min_size = image_paras [ \"min_size\" ] min_depth = image_paras [ \"min_depth\" ] interval = image_paras [ \"interval\" ] resolution = image_paras [ \"resolution\" ] return no_data , min_size , min_depth , interval , resolution","title":"get_image_paras()"},{"location":"slicing/#lidar.slicing.get_min_max_nodata","text":"Gets the minimum, maximum, and no_data value of a numpy array. Parameters: Name Type Description Default image np.array The numpy array containing the image. required Returns: Type Description tuple The minimum, maximum, and no_data value. Source code in lidar/slicing.py def get_min_max_nodata ( image ): \"\"\"Gets the minimum, maximum, and no_data value of a numpy array. Args: image (np.array): The numpy array containing the image. Returns: tuple: The minimum, maximum, and no_data value. \"\"\" max_elev = np . max ( image ) nodata = pow ( 10 , math . floor ( math . log10 ( np . max ( image ))) + 2 ) - 1 # assign no data value image [ image <= 0 ] = nodata # change no data value min_elev = np . min ( image ) return min_elev , max_elev , nodata","title":"get_min_max_nodata()"},{"location":"slicing/#lidar.slicing.getMetadata","text":"Gets rdarray metadata. Parameters: Name Type Description Default img rdarray The richDEM array containing the image. required Returns: Type Description tuple no_data, projection, geotransform, cell_size Source code in lidar/slicing.py def getMetadata ( img ): \"\"\"Gets rdarray metadata. Args: img (rdarray): The richDEM array containing the image. Returns: tuple: no_data, projection, geotransform, cell_size \"\"\" no_data = img . no_data projection = img . projection geotransform = img . geotransform cell_size = np . round ( geotransform [ 1 ], decimals = 2 ) return no_data , projection , geotransform , cell_size","title":"getMetadata()"},{"location":"slicing/#lidar.slicing.img_to_shp","text":"Converts images in a selected folder to shapefiles Parameters: Name Type Description Default in_img_dir str The input iimage directory. required out_shp_dir str The output shapefile directory. required Source code in lidar/slicing.py def img_to_shp ( in_img_dir , out_shp_dir ): \"\"\"Converts images in a selected folder to shapefiles Args: in_img_dir (str): The input iimage directory. out_shp_dir (str): The output shapefile directory. \"\"\" img_files = os . listdir ( in_img_dir ) for img_file in img_files : if img_file . endswith ( \".tif\" ): img_filename = os . path . join ( in_img_dir , img_file ) shp_filename = os . path . join ( out_shp_dir , img_file . replace ( \"tif\" , \"shp\" )) polygonize ( img_filename , shp_filename )","title":"img_to_shp()"},{"location":"slicing/#lidar.slicing.levelSet","text":"Identifies nested depressions using level-set method. Parameters: Name Type Description Default img np.array The numpy array containing the image. required region_id int The unique id of the region. required obj_uid int The object id of the region. required image_paras dict The dictionary containing image parameters. required Returns: Type Description tuple (level image, depression list) Source code in lidar/slicing.py def levelSet ( img , region_id , obj_uid , image_paras ): \"\"\"Identifies nested depressions using level-set method. Args: img (np.array): The numpy array containing the image. region_id (int): The unique id of the region. obj_uid (int): The object id of the region. image_paras (dict): The dictionary containing image parameters. Returns: tuple: (level image, depression list) \"\"\" # unzip input parameters from dict no_data , min_size , min_depth , interval , resolution = get_image_paras ( image_paras ) level_img = np . zeros ( img . shape ) # init output level image # flood_img = np.zeros(img.shape) # init output flood time image max_elev = np . max ( img ) img [ img == 0 ] = no_data min_elev = np . min ( img ) print ( \"Processing Region # {} ...\" . format ( region_id )) # print(\"=========================================================================== Region: {}\".format(region_id)) unique_id = obj_uid parent_ids = {} # store current parent depressions nbr_ids = {} # store the inner-neighbor ids of current parent depressions dep_list = [] # list for storing depressions ( rows , cols ) = img . shape if rows == 1 or cols == 1 : # if the depression is a horizontal or vertical line cells = rows * cols size = cells * pow ( resolution , 2 ) # depression size max_depth = max_elev - min_elev mean_depth = ( max_elev * cells - np . sum ( img )) / cells volume = mean_depth * cells * pow ( resolution , 2 ) unique_id += 1 level = 1 perimeter = cells * resolution major_axis = cells * resolution minor_axis = resolution area_bbox_ratio = 1 if rows == 1 : elongatedness = cols eccentricity = 1 orientation = 0 else : elongatedness = rows eccentricity = 1 orientation = 90 dep_list . append ( Depression ( unique_id , level , cells , size , volume , mean_depth , max_depth , min_elev , max_elev , [], region_id , perimeter , major_axis , minor_axis , elongatedness , eccentricity , orientation , area_bbox_ratio )) level_img = np . ones ( img . shape ) del img return level_img , dep_list for elev in np . arange ( max_elev , min_elev , interval ): # slicing operation using top-down approach img [ img > elev ] = 0 # set elevation higher than xy-plane to zero label_objects , nb_labels = regionGroup ( img , min_size , no_data ) # print('slicing elev = {:.2f}, number of objects = {}'.format(elev, nb_labels)) if nb_labels == 0 : # if slicing results in no objects, quit break # objects = measure.regionprops(label_objects, img, coordinates='xy') objects = measure . regionprops ( label_objects , img ) for i , object in enumerate ( objects ): ( row , col ) = object . coords [ 0 ] # get a boundary cell bbox = object . bbox if len ( parent_ids ) == 0 : # This is the first depression, maximum depression # print(\"This is the maximum depression extent.\") cells = object . area size = cells * pow ( resolution , 2 ) # depression size max_depth = object . max_intensity - object . min_intensity # depression max depth mean_depth = ( object . max_intensity * cells - np . sum ( object . intensity_image )) / cells # depression mean depth volume = mean_depth * cells * pow ( resolution , 2 ) # depression volume # spill_elev = object.max_intensity # to be implemented min_elev = object . min_intensity # depression min elevation max_elev = object . max_intensity # depression max elevation # print(\"size = {}, max depth = {:.2f}, mean depth = {:.2f}, volume = {:.2f}, spill elev = {:.2f}\".format( # size, max_depth, mean_depth, volume, spill_elev)) unique_id += 1 level = 1 perimeter = object . perimeter * resolution major_axis = object . major_axis_length * resolution minor_axis = object . minor_axis_length * resolution if minor_axis == 0 : minor_axis = resolution elongatedness = major_axis * 1.0 / minor_axis eccentricity = object . eccentricity orientation = object . orientation / 3.1415 * 180 area_bbox_ratio = object . extent dep_list . append ( Depression ( unique_id , level , cells , size , volume , mean_depth , max_depth , min_elev , max_elev ,[], region_id , perimeter , major_axis , minor_axis , elongatedness , eccentricity , orientation , area_bbox_ratio )) parent_ids [ unique_id ] = 0 # number of inner neighbors nbr_ids [ unique_id ] = [] # ids of inner neighbors tmp_img = np . zeros ( object . image . shape ) tmp_img [ object . image ] = unique_id writeObject ( level_img , tmp_img , bbox ) # write the object to the final image else : # identify inner neighbors of parent depressions # print(\"current id: {}\".format(parent_ids.keys())) # (row, col) = object.coords[0] parent_id = level_img [ row , col ] parent_ids [ parent_id ] += 1 nbr_ids [ parent_id ] . append ( i ) for key in parent_ids . copy (): # check how many inner neighbors each upper level depression has if parent_ids [ key ] > 1 : # if the parent has two or more children # print(\"Object id: {} has split into {} objects\".format(key, parent_ids[key])) new_parent_keys = nbr_ids [ key ] for new_key in new_parent_keys : object = objects [ new_key ] cells = object . area size = cells * pow ( resolution , 2 ) max_depth = object . max_intensity - object . min_intensity mean_depth = ( object . max_intensity * cells - np . sum ( object . intensity_image )) / cells volume = mean_depth * cells * pow ( resolution , 2 ) spill_elev = object . max_intensity min_elev = object . min_intensity max_elev = object . max_intensity # print(\" -- size = {}, max depth = {:.2f}, mean depth = {:.2f}, volume = {:.2f}, spill elev = {:.2f}\".format( # size, max_depth, mean_depth, volume, spill_elev)) unique_id += 1 level = 1 perimeter = object . perimeter * resolution major_axis = object . major_axis_length * resolution minor_axis = object . minor_axis_length * resolution if minor_axis == 0 : minor_axis = resolution elongatedness = major_axis * 1.0 / minor_axis eccentricity = object . eccentricity orientation = object . orientation / 3.1415 * 180 area_bbox_ratio = object . extent dep_list . append ( Depression ( unique_id , level , cells , size , volume , mean_depth , max_depth , min_elev , max_elev , [], region_id , perimeter , major_axis , minor_axis , elongatedness , eccentricity , orientation , area_bbox_ratio )) dep_list [ key - 1 - obj_uid ] . inNbrId . append ( unique_id ) parent_ids [ unique_id ] = 0 nbr_ids [ unique_id ] = [] bbox = object . bbox tmp_img = np . zeros ( object . image . shape ) tmp_img [ object . image ] = unique_id writeObject ( level_img , tmp_img , bbox ) if key in parent_ids . keys (): # remove parent id that has split parent_ids . pop ( key ) else : parent_ids [ key ] = 0 # if a parent depression has not split, keep it nbr_ids [ key ] = [] # for dep in dep_list: # print(\"id: {} has children {}\".format(dep.id, dep.inNbrId)) dep_list = updateLevel ( dep_list , obj_uid ) # update the inner neighbors of each depression # for dep in dep_list: # print(\"id: {} is level {}\".format(dep.id, dep.level)) del img return level_img , dep_list","title":"levelSet()"},{"location":"slicing/#lidar.slicing.np2rdarray","text":"Converts numpy array to rdarray. Parameters: Name Type Description Default in_array np.array The input numpy array containing the image. required no_data float The no_data value of the image. required projection str The projection coordinate system of the image. required geotransform str The geotransform of the image. required Returns: Type Description rdarray The richDEM array containing the image. Source code in lidar/slicing.py def np2rdarray ( in_array , no_data , projection , geotransform ): \"\"\"Converts numpy array to rdarray. Args: in_array (np.array): The input numpy array containing the image. no_data (float): The no_data value of the image. projection (str): The projection coordinate system of the image. geotransform (str): The geotransform of the image. Returns: rdarray: The richDEM array containing the image. \"\"\" out_array = rd . rdarray ( in_array , no_data = no_data ) out_array . projection = projection out_array . geotransform = geotransform return out_array","title":"np2rdarray()"},{"location":"slicing/#lidar.slicing.obj_to_level","text":"Derives depression level image based on the depression id image and depression list. Parameters: Name Type Description Default obj_img np.array The numpy array containing the object image. required dep_list list A list containing depression info. required Returns: Type Description np.array The numpy array containing the object level image. Source code in lidar/slicing.py def obj_to_level ( obj_img , dep_list ): \"\"\"Derives depression level image based on the depression id image and depression list. Args: obj_img (np.array): The numpy array containing the object image. dep_list (list): A list containing depression info. Returns: np.array: The numpy array containing the object level image. \"\"\" level_img = np . copy ( obj_img ) max_id = int ( np . max ( level_img )) # print(\"max id = \" + str(max_id)) if max_id > 0 : min_id = int ( np . min ( level_img [ np . nonzero ( level_img )])) # print(\"min_id = \" + str(min_id)) for i in range ( min_id , max_id + 1 ): level_img [ level_img == i ] = dep_list [ i - 1 ] . level + max_id level_img = level_img - max_id return level_img","title":"obj_to_level()"},{"location":"slicing/#lidar.slicing.polygonize","text":"Converts a raster image to vector. Parameters: Name Type Description Default img str File path to the input image. required shp_path str File path to the output shapefile. required Source code in lidar/slicing.py def polygonize ( img , shp_path ): \"\"\"Converts a raster image to vector. Args: img (str): File path to the input image. shp_path (str): File path to the output shapefile. \"\"\" # mapping between gdal type and ogr field type type_mapping = { gdal . GDT_Byte : ogr . OFTInteger , gdal . GDT_UInt16 : ogr . OFTInteger , gdal . GDT_Int16 : ogr . OFTInteger , gdal . GDT_UInt32 : ogr . OFTInteger , gdal . GDT_Int32 : ogr . OFTInteger , gdal . GDT_Float32 : ogr . OFTReal , gdal . GDT_Float64 : ogr . OFTReal , gdal . GDT_CInt16 : ogr . OFTInteger , gdal . GDT_CInt32 : ogr . OFTInteger , gdal . GDT_CFloat32 : ogr . OFTReal , gdal . GDT_CFloat64 : ogr . OFTReal } ds = gdal . Open ( img ) prj = ds . GetProjection () srcband = ds . GetRasterBand ( 1 ) dst_layername = \"Shape\" drv = ogr . GetDriverByName ( \"ESRI Shapefile\" ) dst_ds = drv . CreateDataSource ( shp_path ) srs = osr . SpatialReference ( wkt = prj ) dst_layer = dst_ds . CreateLayer ( dst_layername , srs = srs ) raster_field = ogr . FieldDefn ( 'id' , type_mapping [ srcband . DataType ]) dst_layer . CreateField ( raster_field ) gdal . Polygonize ( srcband , srcband , dst_layer , 0 , [], callback = None ) del img , ds , srcband , dst_ds , dst_layer","title":"polygonize()"},{"location":"slicing/#lidar.slicing.regionGroup","text":"IdentifIies regions based on region growing method Parameters: Name Type Description Default img_array np.array The numpy array containing the image. required min_size int The minimum number of pixels to be considered as a depression. required no_data float The no_data value of the image. required Returns: Type Description tuple The labelled objects and total number of labels. Source code in lidar/slicing.py def regionGroup ( img_array , min_size , no_data ): \"\"\"IdentifIies regions based on region growing method Args: img_array (np.array): The numpy array containing the image. min_size (int): The minimum number of pixels to be considered as a depression. no_data (float): The no_data value of the image. Returns: tuple: The labelled objects and total number of labels. \"\"\" img_array [ img_array == no_data ] = 0 label_objects , nb_labels = ndimage . label ( img_array ) sizes = np . bincount ( label_objects . ravel ()) mask_sizes = sizes > min_size mask_sizes [ 0 ] = 0 image_cleaned = mask_sizes [ label_objects ] label_objects , nb_labels = ndimage . label ( image_cleaned ) # nb_labels is the total number of objects. 0 represents background object. return label_objects , nb_labels","title":"regionGroup()"},{"location":"slicing/#lidar.slicing.set_image_paras","text":"Sets the input image parameters for level-set method. Parameters: Name Type Description Default no_data float The no_data value of the input DEM. required min_size int The minimum nuber of pixels to be considered as a depressioin. required min_depth float The minimum depth to be considered as a depression. required interval float The slicing interval. required resolution float The spatial resolution of the DEM. required Returns: Type Description dict A dictionary containing image parameters. Source code in lidar/slicing.py def set_image_paras ( no_data , min_size , min_depth , interval , resolution ): \"\"\"Sets the input image parameters for level-set method. Args: no_data (float): The no_data value of the input DEM. min_size (int): The minimum nuber of pixels to be considered as a depressioin. min_depth (float): The minimum depth to be considered as a depression. interval (float): The slicing interval. resolution (float): The spatial resolution of the DEM. Returns: dict: A dictionary containing image parameters. \"\"\" image_paras = {} image_paras [ \"no_data\" ] = no_data image_paras [ \"min_size\" ] = min_size image_paras [ \"min_depth\" ] = min_depth image_paras [ \"interval\" ] = interval image_paras [ \"resolution\" ] = resolution return image_paras","title":"set_image_paras()"},{"location":"slicing/#lidar.slicing.updateLevel","text":"Updates the inner neighbors of each depression. Parameters: Name Type Description Default dep_list list A list containing depression info. required obj_uid int The unique id of an object. required Returns: Type Description list A list containing depression info. Source code in lidar/slicing.py def updateLevel ( dep_list , obj_uid ): \"\"\"Updates the inner neighbors of each depression. Args: dep_list (list): A list containing depression info. obj_uid (int): The unique id of an object. Returns: list: A list containing depression info. \"\"\" for dep in reversed ( dep_list ): if len ( dep . inNbrId ) == 0 : dep . level = 1 else : max_children_level = 0 for id in dep . inNbrId : if dep_list [ id - 1 - obj_uid ] . level > max_children_level : max_children_level = dep_list [ id - 1 - obj_uid ] . level dep . level = max_children_level + 1 return dep_list","title":"updateLevel()"},{"location":"slicing/#lidar.slicing.write_dep_csv","text":"Saves the depression list to a CSV file. Parameters: Name Type Description Default dep_list list A list containing depression info. required csv_file str File path to the output CSV file. required Source code in lidar/slicing.py def write_dep_csv ( dep_list , csv_file ): \"\"\"Saves the depression list to a CSV file. Args: dep_list (list): A list containing depression info. csv_file (str): File path to the output CSV file. \"\"\" csv = open ( csv_file , \"w\" ) header = \"id\" + \",\" + \"level\" + \",\" + \"count\" + \",\" + \"area\" + \",\" + \"volume\" + \",\" + \"avg-depth\" + \",\" + \"max-depth\" + \",\" + \\ \"min-elev\" + \",\" + \"max-elev\" + \",\" + \"children-id\" + \",\" + \"region-id\" + \",\" + \"perimeter\" + \",\" + \"major-axis\" + \\ \",\" + \"minor-axis\" + \",\" + \"elongatedness\" + \",\" + \"eccentricity\" + \",\" + \"orientation\" + \",\" + \\ \"area-bbox-ratio\" csv . write ( header + \" \\n \" ) for dep in dep_list : # id, level, size, volume, meanDepth, maxDepth, minElev, bndElev, inNbrId, nbrId = 0 line = \" {} , {} , {} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {} , {} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} , {:.2f} ,\" \\ \" {:.2f} \" . format ( dep . id , dep . level , dep . count , dep . size , dep . volume , dep . meanDepth , dep . maxDepth , dep . minElev , dep . bndElev , str ( dep . inNbrId ) . replace ( \",\" , \":\" ), dep . regionId , dep . perimeter , dep . major_axis , dep . minor_axis , dep . elongatedness , dep . eccentricity , dep . orientation , dep . area_bbox_ratio ) csv . write ( line + \" \\n \" ) csv . close ()","title":"write_dep_csv()"},{"location":"slicing/#lidar.slicing.writeObject","text":"Writes depression objects to the original image. Parameters: Name Type Description Default img_array np.array The output image array. required obj_array np.array The numpy array containing depression objects. required bbox list The bounding box of the depression object. required Returns: Type Description np.array The numpy array containing the depression objects. Source code in lidar/slicing.py def writeObject ( img_array , obj_array , bbox ): \"\"\"Writes depression objects to the original image. Args: img_array (np.array): The output image array. obj_array (np.array): The numpy array containing depression objects. bbox (list): The bounding box of the depression object. Returns: np.array: The numpy array containing the depression objects. \"\"\" min_row , min_col , max_row , max_col = bbox roi = img_array [ min_row : max_row , min_col : max_col ] roi [ obj_array > 0 ] = obj_array [ obj_array > 0 ] return img_array","title":"writeObject()"},{"location":"slicing/#lidar.slicing.writeRaster","text":"Saves an numpy array as a GeoTIFF. Parameters: Name Type Description Default arr np.array The numpy array containing the image. required out_path str The file path to the output GeoTIFF. required template str The file path to the template image containing projection info. required Returns: Type Description np.array The numpy array containing the image. Source code in lidar/slicing.py def writeRaster ( arr , out_path , template ): \"\"\"Saves an numpy array as a GeoTIFF. Args: arr (np.array): The numpy array containing the image. out_path (str): The file path to the output GeoTIFF. template (str): The file path to the template image containing projection info. Returns: np.array: The numpy array containing the image. \"\"\" no_data = 0 # First of all, gather some information from the template file data = gdal . Open ( template ) [ cols , rows ] = arr . shape trans = data . GetGeoTransform () proj = data . GetProjection () # nodatav = 0 #data.GetNoDataValue() # Create the file, using the information from the template file outdriver = gdal . GetDriverByName ( \"GTiff\" ) # http://www.gdal.org/gdal_8h.html # GDT_Byte = 1, GDT_UInt16 = 2, GDT_UInt32 = 4, GDT_Int32 = 5, GDT_Float32 = 6, outdata = outdriver . Create ( str ( out_path ), rows , cols , 1 , gdal . GDT_UInt32 ) # Write the array to the file, which is the original array in this example outdata . GetRasterBand ( 1 ) . WriteArray ( arr ) # Set a no data value if required outdata . GetRasterBand ( 1 ) . SetNoDataValue ( no_data ) # Georeference the image outdata . SetGeoTransform ( trans ) # Write projection information outdata . SetProjection ( proj ) return arr","title":"writeRaster()"},{"location":"usage/","text":"Usage \u00b6 The images below show real-world examples of the level set method for delineating nested depressions in the Cottonwood Lake Study Area (CLSA), North Dakota. More test datasets (e.g., the Pipestem watershed in the Prairie Pothole Region of North Dakota) can be downloaded from http://gishub.org/2019-JAWRA-Data The following example was conducted on a 64-bit Linux machine with a quad-core Intel i7-7700 CPU and 16 GB RAM. The average running time of the algorithm for this DEM was 0.75 seconds.","title":"Usage"},{"location":"usage/#usage","text":"The images below show real-world examples of the level set method for delineating nested depressions in the Cottonwood Lake Study Area (CLSA), North Dakota. More test datasets (e.g., the Pipestem watershed in the Prairie Pothole Region of North Dakota) can be downloaded from http://gishub.org/2019-JAWRA-Data The following example was conducted on a 64-bit Linux machine with a quad-core Intel i7-7700 CPU and 16 GB RAM. The average running time of the algorithm for this DEM was 0.75 seconds.","title":"Usage"},{"location":"utilities/","text":"utilities module \u00b6 check_install ( package ) \u00b6 Checks whether a package is installed. If not, it will install the package. Parameters: Name Type Description Default package str The name of the package to check. required Source code in lidar/utilities.py def check_install ( package ): \"\"\"Checks whether a package is installed. If not, it will install the package. Args: package (str): The name of the package to check. \"\"\" import subprocess try : __import__ ( package ) # print('{} is already installed.'.format(package)) except ImportError : print ( \" {} is not installed. Installing ...\" . format ( package )) try : subprocess . check_call ([ \"python\" , \"-m\" , \"pip\" , \"install\" , package ]) except Exception as e : print ( \"Failed to install {} \" . format ( package )) print ( e ) print ( \" {} has been installed successfully.\" . format ( package )) clone_repo ( out_dir = '.' , unzip = True ) \u00b6 Clones the lidar GitHub repository. Parameters: Name Type Description Default out_dir str Output folder for the repo. Defaults to '.'. '.' unzip bool Whether to unzip the repository. Defaults to True. True Source code in lidar/utilities.py def clone_repo ( out_dir = \".\" , unzip = True ): \"\"\"Clones the lidar GitHub repository. Args: out_dir (str, optional): Output folder for the repo. Defaults to '.'. unzip (bool, optional): Whether to unzip the repository. Defaults to True. \"\"\" url = \"https://github.com/giswqs/lidar/archive/master.zip\" filename = \"lidar-master.zip\" download_from_url ( url , out_file_name = filename , out_dir = out_dir , unzip = unzip ) csv_points_to_shp ( in_csv , out_shp , latitude = 'latitude' , longitude = 'longitude' ) \u00b6 Converts a csv file containing points (latitude, longitude) into a shapefile. Parameters: Name Type Description Default in_csv str File path or HTTP URL to the input csv file. For example, https://raw.githubusercontent.com/giswqs/data/main/world/world_cities.csv required out_shp str File path to the output shapefile. required latitude str Column name for the latitude column. Defaults to 'latitude'. 'latitude' longitude str Column name for the longitude column. Defaults to 'longitude'. 'longitude' Source code in lidar/utilities.py def csv_points_to_shp ( in_csv , out_shp , latitude = \"latitude\" , longitude = \"longitude\" ): \"\"\"Converts a csv file containing points (latitude, longitude) into a shapefile. Args: in_csv (str): File path or HTTP URL to the input csv file. For example, https://raw.githubusercontent.com/giswqs/data/main/world/world_cities.csv out_shp (str): File path to the output shapefile. latitude (str, optional): Column name for the latitude column. Defaults to 'latitude'. longitude (str, optional): Column name for the longitude column. Defaults to 'longitude'. \"\"\" import whitebox if in_csv . startswith ( \"http\" ) and in_csv . endswith ( \".csv\" ): out_dir = os . path . join ( os . path . expanduser ( \"~\" ), \"Downloads\" ) out_name = os . path . basename ( in_csv ) if not os . path . exists ( out_dir ): os . makedirs ( out_dir ) download_from_url ( in_csv , out_dir = out_dir ) in_csv = os . path . join ( out_dir , out_name ) wbt = whitebox . WhiteboxTools () in_csv = os . path . abspath ( in_csv ) out_shp = os . path . abspath ( out_shp ) if not os . path . exists ( in_csv ): raise Exception ( \"The provided csv file does not exist.\" ) with open ( in_csv , encoding = \"utf-8\" ) as csv_file : reader = csv . DictReader ( csv_file ) fields = reader . fieldnames xfield = fields . index ( longitude ) yfield = fields . index ( latitude ) wbt . csv_points_to_vector ( in_csv , out_shp , xfield = xfield , yfield = yfield , epsg = 4326 ) csv_to_shp ( in_csv , out_shp , latitude = 'latitude' , longitude = 'longitude' ) \u00b6 Converts a csv file with latlon info to a point shapefile. Parameters: Name Type Description Default in_csv str The input csv file containing longitude and latitude columns. required out_shp str The file path to the output shapefile. required latitude str The column name of the latitude column. Defaults to 'latitude'. 'latitude' longitude str The column name of the longitude column. Defaults to 'longitude'. 'longitude' Source code in lidar/utilities.py def csv_to_shp ( in_csv , out_shp , latitude = \"latitude\" , longitude = \"longitude\" ): \"\"\"Converts a csv file with latlon info to a point shapefile. Args: in_csv (str): The input csv file containing longitude and latitude columns. out_shp (str): The file path to the output shapefile. latitude (str, optional): The column name of the latitude column. Defaults to 'latitude'. longitude (str, optional): The column name of the longitude column. Defaults to 'longitude'. \"\"\" import csv import shapefile as shp if in_csv . startswith ( \"http\" ) and in_csv . endswith ( \".csv\" ): out_dir = os . path . join ( os . path . expanduser ( \"~\" ), \"Downloads\" ) out_name = os . path . basename ( in_csv ) if not os . path . exists ( out_dir ): os . makedirs ( out_dir ) download_from_url ( in_csv , out_dir = out_dir ) in_csv = os . path . join ( out_dir , out_name ) out_dir = os . path . dirname ( out_shp ) if not os . path . exists ( out_dir ): os . makedirs ( out_dir ) try : points = shp . Writer ( out_shp , shapeType = shp . POINT ) with open ( in_csv , encoding = \"utf-8\" ) as csvfile : csvreader = csv . DictReader ( csvfile ) header = csvreader . fieldnames [ points . field ( field ) for field in header ] for row in csvreader : points . point (( float ( row [ longitude ])), ( float ( row [ latitude ]))) points . record ( * tuple ([ row [ f ] for f in header ])) out_prj = out_shp . replace ( \".shp\" , \".prj\" ) with open ( out_prj , \"w\" ) as f : prj_str = 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]] ' f . write ( prj_str ) except Exception as e : print ( e ) download_from_gdrive ( gfile_url , file_name , out_dir = '.' , unzip = True , verbose = True ) \u00b6 Download a file shared via Google Drive (e.g., https://drive.google.com/file/d/18SUo_HcDGltuWYZs1s7PpOmOq_FvFn04/view?usp=sharing) Parameters: Name Type Description Default gfile_url str The Google Drive shared file URL required file_name str The output file name to use. required out_dir str The output directory. Defaults to '.'. '.' unzip bool Whether to unzip the output file if it is a zip file. Defaults to True. True verbose bool Whether to display or not the output of the function True Source code in lidar/utilities.py def download_from_gdrive ( gfile_url , file_name , out_dir = \".\" , unzip = True , verbose = True ): \"\"\"Download a file shared via Google Drive (e.g., https://drive.google.com/file/d/18SUo_HcDGltuWYZs1s7PpOmOq_FvFn04/view?usp=sharing) Args: gfile_url (str): The Google Drive shared file URL file_name (str): The output file name to use. out_dir (str, optional): The output directory. Defaults to '.'. unzip (bool, optional): Whether to unzip the output file if it is a zip file. Defaults to True. verbose (bool, optional): Whether to display or not the output of the function \"\"\" try : from google_drive_downloader import GoogleDriveDownloader as gdd except ImportError : print ( \"GoogleDriveDownloader package not installed. Installing ...\" ) subprocess . check_call ( [ \"python\" , \"-m\" , \"pip\" , \"install\" , \"googledrivedownloader\" ] ) from google_drive_downloader import GoogleDriveDownloader as gdd file_id = gfile_url . split ( \"/\" )[ 5 ] if verbose : print ( \"Google Drive file id: {} \" . format ( file_id )) dest_path = os . path . join ( out_dir , file_name ) gdd . download_file_from_google_drive ( file_id , dest_path , True , unzip ) return download_from_url ( url , out_file_name = None , out_dir = '.' , unzip = True , verbose = True ) \u00b6 Download a file from a URL (e.g., https://github.com/giswqs/whitebox/raw/master/examples/testdata.zip) Parameters: Name Type Description Default url str The HTTP URL to download. required out_file_name str The output file name to use. Defaults to None. None out_dir str The output directory to use. Defaults to '.'. '.' unzip bool Whether to unzip the downloaded file if it is a zip file. Defaults to True. True verbose bool Whether to display or not the output of the function True Source code in lidar/utilities.py def download_from_url ( url , out_file_name = None , out_dir = \".\" , unzip = True , verbose = True ): \"\"\"Download a file from a URL (e.g., https://github.com/giswqs/whitebox/raw/master/examples/testdata.zip) Args: url (str): The HTTP URL to download. out_file_name (str, optional): The output file name to use. Defaults to None. out_dir (str, optional): The output directory to use. Defaults to '.'. unzip (bool, optional): Whether to unzip the downloaded file if it is a zip file. Defaults to True. verbose (bool, optional): Whether to display or not the output of the function \"\"\" in_file_name = os . path . basename ( url ) if out_file_name is None : out_file_name = in_file_name out_file_path = os . path . join ( os . path . abspath ( out_dir ), out_file_name ) if verbose : print ( \"Downloading {} ...\" . format ( url )) try : urllib . request . urlretrieve ( url , out_file_path ) except Exception : raise Exception ( \"The URL is invalid. Please double check the URL.\" ) final_path = out_file_path if unzip : # if it is a zip file if \".zip\" in out_file_name : if verbose : print ( \"Unzipping {} ...\" . format ( out_file_name )) with zipfile . ZipFile ( out_file_path , \"r\" ) as zip_ref : zip_ref . extractall ( out_dir ) final_path = os . path . join ( os . path . abspath ( out_dir ), out_file_name . replace ( \".zip\" , \"\" ) ) # if it is a tar file if \".tar\" in out_file_name : if verbose : print ( \"Unzipping {} ...\" . format ( out_file_name )) with tarfile . open ( out_file_path , \"r\" ) as tar_ref : tar_ref . extractall ( out_dir ) final_path = os . path . join ( os . path . abspath ( out_dir ), out_file_name . replace ( \".tart\" , \"\" ) ) if verbose : print ( \"Data downloaded to: {} \" . format ( final_path )) return in_colab_shell () \u00b6 Tests if the code is being executed within Google Colab. Source code in lidar/utilities.py def in_colab_shell (): \"\"\"Tests if the code is being executed within Google Colab.\"\"\" try : import google.colab # pylint: disable=unused-variable return True except ImportError : return False is_drive_mounted () \u00b6 Checks whether Google Drive is mounted in Google Colab. Returns: Type Description bool Returns True if Google Drive is mounted, False otherwise. Source code in lidar/utilities.py def is_drive_mounted (): \"\"\"Checks whether Google Drive is mounted in Google Colab. Returns: bool: Returns True if Google Drive is mounted, False otherwise. \"\"\" drive_path = \"/content/drive/My Drive\" if os . path . exists ( drive_path ): return True else : return False is_tool ( name ) \u00b6 Check whether name is on PATH and marked as executable. Source code in lidar/utilities.py def is_tool ( name ): \"\"\"Check whether `name` is on PATH and marked as executable.\"\"\" from shutil import which return which ( name ) is not None random_string ( string_length = 3 ) \u00b6 Generates a random string of fixed length. Parameters: Name Type Description Default string_length int Fixed length. Defaults to 3. 3 Returns: Type Description str A random string Source code in lidar/utilities.py def random_string ( string_length = 3 ): \"\"\"Generates a random string of fixed length. Args: string_length (int, optional): Fixed length. Defaults to 3. Returns: str: A random string \"\"\" import random import string # random.seed(1001) letters = string . ascii_lowercase return \"\" . join ( random . choice ( letters ) for i in range ( string_length )) update_package () \u00b6 Updates the lidar package from the lidar GitHub repository without the need to use pip or conda. In this way, I don't have to keep updating pypi and conda-forge with every minor update of the package. Source code in lidar/utilities.py def update_package (): \"\"\"Updates the lidar package from the lidar GitHub repository without the need to use pip or conda. In this way, I don't have to keep updating pypi and conda-forge with every minor update of the package. \"\"\" import shutil try : download_dir = os . path . join ( os . path . expanduser ( \"~\" ), \"Downloads\" ) if not os . path . exists ( download_dir ): os . makedirs ( download_dir ) clone_repo ( out_dir = download_dir ) pkg_dir = os . path . join ( download_dir , \"lidar-master\" ) work_dir = os . getcwd () os . chdir ( pkg_dir ) if shutil . which ( \"pip\" ) is None : cmd = \"pip3 install .\" else : cmd = \"pip install .\" os . system ( cmd ) os . chdir ( work_dir ) print ( \" \\n Please comment out 'lidar.update_package()' and restart the kernel to take effect: \\n Jupyter menu -> Kernel -> Restart & Clear Output\" ) except Exception as e : raise Exception ( e )","title":"utilities module"},{"location":"utilities/#utilities-module","text":"","title":"utilities module"},{"location":"utilities/#lidar.utilities.check_install","text":"Checks whether a package is installed. If not, it will install the package. Parameters: Name Type Description Default package str The name of the package to check. required Source code in lidar/utilities.py def check_install ( package ): \"\"\"Checks whether a package is installed. If not, it will install the package. Args: package (str): The name of the package to check. \"\"\" import subprocess try : __import__ ( package ) # print('{} is already installed.'.format(package)) except ImportError : print ( \" {} is not installed. Installing ...\" . format ( package )) try : subprocess . check_call ([ \"python\" , \"-m\" , \"pip\" , \"install\" , package ]) except Exception as e : print ( \"Failed to install {} \" . format ( package )) print ( e ) print ( \" {} has been installed successfully.\" . format ( package ))","title":"check_install()"},{"location":"utilities/#lidar.utilities.clone_repo","text":"Clones the lidar GitHub repository. Parameters: Name Type Description Default out_dir str Output folder for the repo. Defaults to '.'. '.' unzip bool Whether to unzip the repository. Defaults to True. True Source code in lidar/utilities.py def clone_repo ( out_dir = \".\" , unzip = True ): \"\"\"Clones the lidar GitHub repository. Args: out_dir (str, optional): Output folder for the repo. Defaults to '.'. unzip (bool, optional): Whether to unzip the repository. Defaults to True. \"\"\" url = \"https://github.com/giswqs/lidar/archive/master.zip\" filename = \"lidar-master.zip\" download_from_url ( url , out_file_name = filename , out_dir = out_dir , unzip = unzip )","title":"clone_repo()"},{"location":"utilities/#lidar.utilities.csv_points_to_shp","text":"Converts a csv file containing points (latitude, longitude) into a shapefile. Parameters: Name Type Description Default in_csv str File path or HTTP URL to the input csv file. For example, https://raw.githubusercontent.com/giswqs/data/main/world/world_cities.csv required out_shp str File path to the output shapefile. required latitude str Column name for the latitude column. Defaults to 'latitude'. 'latitude' longitude str Column name for the longitude column. Defaults to 'longitude'. 'longitude' Source code in lidar/utilities.py def csv_points_to_shp ( in_csv , out_shp , latitude = \"latitude\" , longitude = \"longitude\" ): \"\"\"Converts a csv file containing points (latitude, longitude) into a shapefile. Args: in_csv (str): File path or HTTP URL to the input csv file. For example, https://raw.githubusercontent.com/giswqs/data/main/world/world_cities.csv out_shp (str): File path to the output shapefile. latitude (str, optional): Column name for the latitude column. Defaults to 'latitude'. longitude (str, optional): Column name for the longitude column. Defaults to 'longitude'. \"\"\" import whitebox if in_csv . startswith ( \"http\" ) and in_csv . endswith ( \".csv\" ): out_dir = os . path . join ( os . path . expanduser ( \"~\" ), \"Downloads\" ) out_name = os . path . basename ( in_csv ) if not os . path . exists ( out_dir ): os . makedirs ( out_dir ) download_from_url ( in_csv , out_dir = out_dir ) in_csv = os . path . join ( out_dir , out_name ) wbt = whitebox . WhiteboxTools () in_csv = os . path . abspath ( in_csv ) out_shp = os . path . abspath ( out_shp ) if not os . path . exists ( in_csv ): raise Exception ( \"The provided csv file does not exist.\" ) with open ( in_csv , encoding = \"utf-8\" ) as csv_file : reader = csv . DictReader ( csv_file ) fields = reader . fieldnames xfield = fields . index ( longitude ) yfield = fields . index ( latitude ) wbt . csv_points_to_vector ( in_csv , out_shp , xfield = xfield , yfield = yfield , epsg = 4326 )","title":"csv_points_to_shp()"},{"location":"utilities/#lidar.utilities.csv_to_shp","text":"Converts a csv file with latlon info to a point shapefile. Parameters: Name Type Description Default in_csv str The input csv file containing longitude and latitude columns. required out_shp str The file path to the output shapefile. required latitude str The column name of the latitude column. Defaults to 'latitude'. 'latitude' longitude str The column name of the longitude column. Defaults to 'longitude'. 'longitude' Source code in lidar/utilities.py def csv_to_shp ( in_csv , out_shp , latitude = \"latitude\" , longitude = \"longitude\" ): \"\"\"Converts a csv file with latlon info to a point shapefile. Args: in_csv (str): The input csv file containing longitude and latitude columns. out_shp (str): The file path to the output shapefile. latitude (str, optional): The column name of the latitude column. Defaults to 'latitude'. longitude (str, optional): The column name of the longitude column. Defaults to 'longitude'. \"\"\" import csv import shapefile as shp if in_csv . startswith ( \"http\" ) and in_csv . endswith ( \".csv\" ): out_dir = os . path . join ( os . path . expanduser ( \"~\" ), \"Downloads\" ) out_name = os . path . basename ( in_csv ) if not os . path . exists ( out_dir ): os . makedirs ( out_dir ) download_from_url ( in_csv , out_dir = out_dir ) in_csv = os . path . join ( out_dir , out_name ) out_dir = os . path . dirname ( out_shp ) if not os . path . exists ( out_dir ): os . makedirs ( out_dir ) try : points = shp . Writer ( out_shp , shapeType = shp . POINT ) with open ( in_csv , encoding = \"utf-8\" ) as csvfile : csvreader = csv . DictReader ( csvfile ) header = csvreader . fieldnames [ points . field ( field ) for field in header ] for row in csvreader : points . point (( float ( row [ longitude ])), ( float ( row [ latitude ]))) points . record ( * tuple ([ row [ f ] for f in header ])) out_prj = out_shp . replace ( \".shp\" , \".prj\" ) with open ( out_prj , \"w\" ) as f : prj_str = 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]] ' f . write ( prj_str ) except Exception as e : print ( e )","title":"csv_to_shp()"},{"location":"utilities/#lidar.utilities.download_from_gdrive","text":"Download a file shared via Google Drive (e.g., https://drive.google.com/file/d/18SUo_HcDGltuWYZs1s7PpOmOq_FvFn04/view?usp=sharing) Parameters: Name Type Description Default gfile_url str The Google Drive shared file URL required file_name str The output file name to use. required out_dir str The output directory. Defaults to '.'. '.' unzip bool Whether to unzip the output file if it is a zip file. Defaults to True. True verbose bool Whether to display or not the output of the function True Source code in lidar/utilities.py def download_from_gdrive ( gfile_url , file_name , out_dir = \".\" , unzip = True , verbose = True ): \"\"\"Download a file shared via Google Drive (e.g., https://drive.google.com/file/d/18SUo_HcDGltuWYZs1s7PpOmOq_FvFn04/view?usp=sharing) Args: gfile_url (str): The Google Drive shared file URL file_name (str): The output file name to use. out_dir (str, optional): The output directory. Defaults to '.'. unzip (bool, optional): Whether to unzip the output file if it is a zip file. Defaults to True. verbose (bool, optional): Whether to display or not the output of the function \"\"\" try : from google_drive_downloader import GoogleDriveDownloader as gdd except ImportError : print ( \"GoogleDriveDownloader package not installed. Installing ...\" ) subprocess . check_call ( [ \"python\" , \"-m\" , \"pip\" , \"install\" , \"googledrivedownloader\" ] ) from google_drive_downloader import GoogleDriveDownloader as gdd file_id = gfile_url . split ( \"/\" )[ 5 ] if verbose : print ( \"Google Drive file id: {} \" . format ( file_id )) dest_path = os . path . join ( out_dir , file_name ) gdd . download_file_from_google_drive ( file_id , dest_path , True , unzip ) return","title":"download_from_gdrive()"},{"location":"utilities/#lidar.utilities.download_from_url","text":"Download a file from a URL (e.g., https://github.com/giswqs/whitebox/raw/master/examples/testdata.zip) Parameters: Name Type Description Default url str The HTTP URL to download. required out_file_name str The output file name to use. Defaults to None. None out_dir str The output directory to use. Defaults to '.'. '.' unzip bool Whether to unzip the downloaded file if it is a zip file. Defaults to True. True verbose bool Whether to display or not the output of the function True Source code in lidar/utilities.py def download_from_url ( url , out_file_name = None , out_dir = \".\" , unzip = True , verbose = True ): \"\"\"Download a file from a URL (e.g., https://github.com/giswqs/whitebox/raw/master/examples/testdata.zip) Args: url (str): The HTTP URL to download. out_file_name (str, optional): The output file name to use. Defaults to None. out_dir (str, optional): The output directory to use. Defaults to '.'. unzip (bool, optional): Whether to unzip the downloaded file if it is a zip file. Defaults to True. verbose (bool, optional): Whether to display or not the output of the function \"\"\" in_file_name = os . path . basename ( url ) if out_file_name is None : out_file_name = in_file_name out_file_path = os . path . join ( os . path . abspath ( out_dir ), out_file_name ) if verbose : print ( \"Downloading {} ...\" . format ( url )) try : urllib . request . urlretrieve ( url , out_file_path ) except Exception : raise Exception ( \"The URL is invalid. Please double check the URL.\" ) final_path = out_file_path if unzip : # if it is a zip file if \".zip\" in out_file_name : if verbose : print ( \"Unzipping {} ...\" . format ( out_file_name )) with zipfile . ZipFile ( out_file_path , \"r\" ) as zip_ref : zip_ref . extractall ( out_dir ) final_path = os . path . join ( os . path . abspath ( out_dir ), out_file_name . replace ( \".zip\" , \"\" ) ) # if it is a tar file if \".tar\" in out_file_name : if verbose : print ( \"Unzipping {} ...\" . format ( out_file_name )) with tarfile . open ( out_file_path , \"r\" ) as tar_ref : tar_ref . extractall ( out_dir ) final_path = os . path . join ( os . path . abspath ( out_dir ), out_file_name . replace ( \".tart\" , \"\" ) ) if verbose : print ( \"Data downloaded to: {} \" . format ( final_path )) return","title":"download_from_url()"},{"location":"utilities/#lidar.utilities.in_colab_shell","text":"Tests if the code is being executed within Google Colab. Source code in lidar/utilities.py def in_colab_shell (): \"\"\"Tests if the code is being executed within Google Colab.\"\"\" try : import google.colab # pylint: disable=unused-variable return True except ImportError : return False","title":"in_colab_shell()"},{"location":"utilities/#lidar.utilities.is_drive_mounted","text":"Checks whether Google Drive is mounted in Google Colab. Returns: Type Description bool Returns True if Google Drive is mounted, False otherwise. Source code in lidar/utilities.py def is_drive_mounted (): \"\"\"Checks whether Google Drive is mounted in Google Colab. Returns: bool: Returns True if Google Drive is mounted, False otherwise. \"\"\" drive_path = \"/content/drive/My Drive\" if os . path . exists ( drive_path ): return True else : return False","title":"is_drive_mounted()"},{"location":"utilities/#lidar.utilities.is_tool","text":"Check whether name is on PATH and marked as executable. Source code in lidar/utilities.py def is_tool ( name ): \"\"\"Check whether `name` is on PATH and marked as executable.\"\"\" from shutil import which return which ( name ) is not None","title":"is_tool()"},{"location":"utilities/#lidar.utilities.random_string","text":"Generates a random string of fixed length. Parameters: Name Type Description Default string_length int Fixed length. Defaults to 3. 3 Returns: Type Description str A random string Source code in lidar/utilities.py def random_string ( string_length = 3 ): \"\"\"Generates a random string of fixed length. Args: string_length (int, optional): Fixed length. Defaults to 3. Returns: str: A random string \"\"\" import random import string # random.seed(1001) letters = string . ascii_lowercase return \"\" . join ( random . choice ( letters ) for i in range ( string_length ))","title":"random_string()"},{"location":"utilities/#lidar.utilities.update_package","text":"Updates the lidar package from the lidar GitHub repository without the need to use pip or conda. In this way, I don't have to keep updating pypi and conda-forge with every minor update of the package. Source code in lidar/utilities.py def update_package (): \"\"\"Updates the lidar package from the lidar GitHub repository without the need to use pip or conda. In this way, I don't have to keep updating pypi and conda-forge with every minor update of the package. \"\"\" import shutil try : download_dir = os . path . join ( os . path . expanduser ( \"~\" ), \"Downloads\" ) if not os . path . exists ( download_dir ): os . makedirs ( download_dir ) clone_repo ( out_dir = download_dir ) pkg_dir = os . path . join ( download_dir , \"lidar-master\" ) work_dir = os . getcwd () os . chdir ( pkg_dir ) if shutil . which ( \"pip\" ) is None : cmd = \"pip3 install .\" else : cmd = \"pip install .\" os . system ( cmd ) os . chdir ( work_dir ) print ( \" \\n Please comment out 'lidar.update_package()' and restart the kernel to take effect: \\n Jupyter menu -> Kernel -> Restart & Clear Output\" ) except Exception as e : raise Exception ( e )","title":"update_package()"}]}